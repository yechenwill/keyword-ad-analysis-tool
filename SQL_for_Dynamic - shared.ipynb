{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\AppData\\Local\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import paramiko\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the directory to where the text file which stores vertica password is\n",
    "pwd = open('..//vertica-pwd.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host = \"e-dcf-07.ame.admarketplace.net\"\n",
    "# port = 22\n",
    "# username = \"tdam\"\n",
    "# password = open('../server-pwd.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL statements have been saved to insert_statements.sql\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "input_tsv_file = 'Draft - Yahoo-Template.tsv'  # Replace with your actual file path\n",
    "output_sql_file = 'insert_statements.sql'    # Replace with desired output path\n",
    "\n",
    "# Load the TSV file\n",
    "data = pd.read_csv(input_tsv_file, sep='\\t')\n",
    "\n",
    "# Initialize an empty list to store SQL statements\n",
    "sql_statements = []\n",
    "\n",
    "# Generate SQL INSERT statements for each row in the data\n",
    "for _, row in data.iterrows():\n",
    "    sql = f\"INSERT INTO ADLANDING_CTAID_LOOKUP (PUB_PUBLISHER_ID, PUBLISHER_NAME, PUB_SUB1, PUB_SUB2, PUB_SUB3, PUB_SUB4, CTAID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP) \" \\\n",
    "          f\"VALUES({row['publisher_id']}, '{row['PUBLISHER_NAME']}', '{row['SUB1']}', '{row['SUB2']}', '{row['SUB3']}', '{row['SUB4']}', 75151, NOW(), NOW());\"\n",
    "    sql_statements.append(sql)\n",
    "\n",
    "# Write the generated SQL statements to a file\n",
    "with open(output_sql_file, 'w') as file:\n",
    "    for statement in sql_statements:\n",
    "        file.write(statement + '\\n')\n",
    "\n",
    "print(f\"SQL statements have been saved to {output_sql_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL statements have been saved to traffic_source_inserts.sql\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the TSV file\n",
    "file_path = 'Draft - Old_TS_Migration.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Function to generate SQL insert statements excluding columns with null values and removing decimal for integers\n",
    "def generate_sql_insert_exclude_nulls(row):\n",
    "    columns = []\n",
    "    values = []\n",
    "    for column in df.columns:\n",
    "        value = row[column]\n",
    "        # Only include non-null values in the SQL statement\n",
    "        if not pd.isnull(value):\n",
    "            # Format value: if it's numeric, remove decimal point if possible\n",
    "            if isinstance(value, (int, float)) and value == int(value):\n",
    "                values.append(f\"'{int(value)}'\")  # Convert to integer format\n",
    "            else:\n",
    "                values.append(f\"'{value}'\")  # Keep original format for non-numeric or non-integer-like values\n",
    "            columns.append(column)\n",
    "\n",
    "    # Construct the SQL statement dynamically based on non-null columns and values\n",
    "    sql_statement = f\"INSERT INTO TRAFFIC_SOURCE ({', '.join(columns)}, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP) VALUES ({', '.join(values)}, NOW(), NOW());\"\n",
    "    return sql_statement\n",
    "\n",
    "# Apply the modified function to each row to generate the list of SQL statements\n",
    "sql_statements = df.apply(generate_sql_insert_exclude_nulls, axis=1)\n",
    "\n",
    "# Define output file path\n",
    "output_file_path = 'traffic_source_inserts.sql'\n",
    "\n",
    "# Write the SQL statements to an output file\n",
    "with open(output_file_path, 'w') as f:\n",
    "    for statement in sql_statements:\n",
    "        f.write(statement + '\\n')\n",
    "\n",
    "print(f\"SQL statements have been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_ = {'unmask':[13027], 'whitelist':[]}\n",
    "date = dt.datetime.strftime(dt.date.today(),'%Y%m%d')\n",
    "\n",
    "if len(input_['unmask']) > 0:\n",
    "    print('USE adminDB_Prod;')\n",
    "    for i in input_['unmask']:\n",
    "        print(\"INSERT INTO RFR_MASK_V3 (FEED_ID, PUBLISHER_ID, RFR_DOMAIN, MASK_DOMAIN, LAST_INSERT_BATCH_ID) VALUES (0, %i, 0, 'NO_MASKING', %s);\"%(i,date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DYNAMIC TILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Add new account to existing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_id':[12791,12827,12859], \n",
    "        'ads': {},\n",
    "        'sub1': ['10141','10150'],\n",
    "        'sub2': ['newtab'],\n",
    "        'sub3': ['75083'],\n",
    "        'sub4': [''],\n",
    "        'account_id': [],\n",
    "        'ts_level_to-copy-ad':3,\n",
    "        'ts_level_to-get-ts':3,\n",
    "        'sub-value-to-copy-ad':'sub1',\n",
    "        'sub-value-to-pass-ad':'sub1',        \n",
    "       'ts_index':'FF_advs_05082024_index.txt',\n",
    "       'cluster_sql':'./clusters/FF_advs_05082024_setup.sql'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_id':[12875], \n",
    "        'ads': {},\n",
    "        'sub1': ['10164'],\n",
    "        'sub2': ['homepage'],\n",
    "        'sub3': ['75099'],\n",
    "        'sub4': [''],\n",
    "        'account_id': [],\n",
    "        'ts_level_to-copy-ad':3,\n",
    "        'ts_level_to-get-ts':3,\n",
    "        'sub-value-to-copy-ad':'sub1',\n",
    "        'sub-value-to-pass-ad':'sub1',        \n",
    "       'ts_index':'tkmaxx_klarnalaybuy_04162024_index.txt',\n",
    "       'cluster_sql':'./clusters/tkmaxx_klarnalaybuy_04162024_setup.sql'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_id':[12845], \n",
    "        'ads': {},\n",
    "        'sub1': ['10154',],\n",
    "        'sub2': ['mobile728x90','mobile300x250','mobile300x600'],\n",
    "        'sub3': ['74301','73634','74875','74022','74986','74319','74857','74939','74925','74649','74038','24038','74495','74251','73804','74929','74949','74671','74713','73588','73780','74843','74609','26026','74701','74022','74319','74983','74933','73974','74894','73634','74875','74857','74939','74925','74649','74038','24038','8654','74251','73804','74929','74373','73686','74711','74949','74671','74713','73588','73780','74609','26026','74701','74983','74991'],\n",
    "        'sub4': [''],\n",
    "        'account_id': [],\n",
    "        'ts_level_to-copy-ad':3,\n",
    "        'ts_level_to-get-ts':3,\n",
    "        'sub-value-to-copy-ad':'sub1',\n",
    "        'sub-value-to-pass-ad':'sub1',        \n",
    "       'ts_index':'TS_index_weatherbugtiles_mobile_advs_04122023_setup.log',\n",
    "       'cluster_sql':'./clusters/weatherbugtiles_mobile_advs_04122023_setup.sql'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_id':[13013,13005,13003], \n",
    "        'ads': {},\n",
    "        'sub1': ['strategist'],\n",
    "        'sub2': ['instagram','sem','paidsocial'],\n",
    "        'sub3': [''],\n",
    "        'sub4': [''],\n",
    "        'account_id': [],\n",
    "        'ts_level_to-copy-ad':2,\n",
    "        'ts_level_to-get-ts':2,\n",
    "        'sub-value-to-copy-ad':'sub1',\n",
    "        'sub-value-to-pass-ad':'sub1',        \n",
    "       'ts_index':'vox_03132024_index.txt',\n",
    "       'cluster_sql':'./clusters/vox_03132024_index_setup.sql'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_id':[12981], \n",
    "        'ads': {},\n",
    "        'sub1': ['10204'],\n",
    "        'sub2': ['anywhere'],\n",
    "        'sub3': ['74301','74777','74983','73634','74875','25116','74887','74022','74986','74319','74925','74939','74991','74649','74038','74863','8654','74481','73804','74521','74929','74929','74929','74929','74929','74993','73686','74711','74949','74671','75033','74867','74755','74997','73588','74609','26026','74919','74701','74894'],\n",
    "        'sub4': [''],\n",
    "        'account_id': [],\n",
    "        'ts_level_to-copy-ad':3,\n",
    "        'ts_level_to-get-ts':3,\n",
    "        'sub-value-to-copy-ad':'sub1',\n",
    "        'sub-value-to-pass-ad':'sub1',        \n",
    "       'ts_index':'sezzletilesapi_anywhere_09282023_setup.txt',\n",
    "       'cluster_sql':'./clusters/sezzletilesapi_anywhere_09282023_setup.sql'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(para['ts_index'],'w') \n",
    "\n",
    "for i in para['pub_id']:\n",
    "    for j in para['sub1']:\n",
    "            for k in para['sub2']:\n",
    "                    for l in para['sub3']:\n",
    "                            for m in para['sub4']:\n",
    "                                line = str(i) + '|' + str(j) + '|' + str(k)+ '|' + str(l) + '|' + str(m)                           \n",
    "                                file.writelines('%s\\n'%line)\n",
    "# print(i,j,k,l)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_id': ['12259','12329','12395','12487','12679','12741','12747','12965'],\n",
    "       'sub3': {75097: \n",
    "                {'kw': [\n",
    "                    {'campaign':'220591',  'adgroup':15623217, 'kw':358295817}\n",
    "                    ,{'campaign':'220589',  'adgroup':15623205, 'kw':358296175}\n",
    "#                     ,{'campaign':'219881',  'adgroup':15417493, 'kw':353692583}\n",
    "#                     ,{'campaign':'219883',  'adgroup':14985435, 'kw':348959587}\n",
    "#                     ,{'campaign':'219885',  'adgroup':15417555, 'kw':353777205}\n",
    "#                     ,{'campaign':'219887',  'adgroup':15417279, 'kw':353505769}\n",
    "#                     ,{'campaign':'219889',  'adgroup':15417285, 'kw':353507295}\n",
    "#                     ,{'campaign':'218597',  'adgroup':15229053, 'kw':349959969}\n",
    "#                     ,{'campaign':'218585',  'adgroup':15229041, 'kw':349959957}\n",
    "#                     ,{'campaign':'',  'adgroup':13996009, 'kw':321096639}\n",
    "#                     ,{'campaign':'',  'adgroup':14012967, 'kw':321464109}\n",
    "#                     ,{'campaign':'',  'adgroup':14012935, 'kw':321463617}\n",
    "#                     ,{'campaign':'',  'adgroup':14012791, 'kw':321454465}\n",
    "#                     ,{'campaign':'',  'adgroup':13996169, 'kw':321102193}\n",
    "#                     ,{'campaign':'',  'adgroup':13995713, 'kw':321087331}\n",
    "                ],\n",
    "                'external':\"\", 'img':''},\n",
    "               },\n",
    "       'ts_index':'tilesDM_viagogo_05132024_index.txt',\n",
    "       'cluster_sql':'./clusters/tilesDM_viagogo_05132024_setup.sql'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_id':[12893], \n",
    "        'ads': {},\n",
    "        'sub1': ['10173'],\n",
    "        'sub2': ['newtab'],\n",
    "        'sub3': ['8654','24038','74245','74713','74609','74671','74843','74896','74437','25176','74613','74905'],\n",
    "        'sub4': [''],\n",
    "        'account_id': [],\n",
    "        'ts_level_to-copy-ad':3,\n",
    "        'ts_level_to-get-ts':3,\n",
    "        'sub-value-to-copy-ad':'sub1',\n",
    "        'sub-value-to-pass-ad':'sub1' ,       \n",
    "       'ts_index':'TS_index_redbricks_advs_11012022_setup.log',\n",
    "       'cluster_sql':'./clusters/redbricks_advs_11012022_setup.sql'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for restructure\n",
    "para = {'pub_id': ['12747','12299'],\n",
    "       'sub3': {\n",
    "       75105: \n",
    "                {'kw': [\n",
    "                    {'campaign':'220655',  'adgroup':15623429, 'kw':358655011}\n",
    "#                     ,{'campaign':'219581',  'adgroup':15412945, 'kw':353127071}\n",
    "#                     ,{'campaign':'219383',  'adgroup':15411243, 'kw':351444687}\n",
    "#                     ,{'campaign':'218733',  'adgroup':15232487, 'kw':350350529}\n",
    "#                     ,{'campaign':'218647',  'adgroup':15229597, 'kw':350265425}\n",
    "#                     ,{'campaign':'218643',  'adgroup':15229369, 'kw':350253113}\n",
    "#                     ,{'campaign':'218595',  'adgroup':15229051, 'kw':349959967}\n",
    "#                     ,{'campaign':'218597',  'adgroup':15229053, 'kw':349959969}\n",
    "#                     ,{'campaign':'218585',  'adgroup':15229041, 'kw':349959957}\n",
    "#                     ,{'campaign':'',  'adgroup':13996009, 'kw':321096639}\n",
    "#                     ,{'campaign':'',  'adgroup':14012967, 'kw':321464109}\n",
    "#                     ,{'campaign':'',  'adgroup':14012935, 'kw':321463617}\n",
    "#                     ,{'campaign':'',  'adgroup':14012791, 'kw':321454465}\n",
    "#                     ,{'campaign':'',  'adgroup':13996169, 'kw':321102193}\n",
    "#                     ,{'campaign':'',  'adgroup':13995713, 'kw':321087331}\n",
    "                ],\n",
    "                'external':\"\", 'img':''},\n",
    "               },\n",
    "       'cluster_sql':'./clusters/dynamic_tiles_dynamictiles_chewy_restructure_20220511.sql'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(para['pub_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "sql = \"\"\"\n",
    "select distinct publisher_id, sub1, sub2 from ampx.traffic_source ats \n",
    "JOIN domainpub.TS_CLUSTER ts ON ats.ID = ts.PUB_ATS_ID \n",
    "where ats.publisher_id in (%s) and level = 2\n",
    "--and sub2 = 'newtab'\n",
    "--and sub2 = 'filetaxes'\n",
    "--and sub2 = 'shopping'\n",
    "--and sub1 in ('10075')\n",
    "--and ats.PUBLISHER_ID||sub2 not in (select distinct publisher_id||sub2 from ampx.traffic_source ats where sub3 = 73812 and level =3 and PUBLISHER_ID in (12379,12361,12395,12339))\n",
    "order by 1,2,3\n",
    "\"\"\"%str(para['pub_id'])[1:-1]\n",
    "\n",
    "sub2 = pd.read_sql(sql,db)\n",
    "\n",
    "para['sub2'] = sub2.to_dict('records')\n",
    "\n",
    "para['tag_id'] = sub2[['publisher_id','sub1']].drop_duplicates().to_dict('records')\n",
    "\n",
    "sub2 = pd.read_sql(sql,db)\n",
    "\n",
    "sql = \"\"\"SELECT DISTINCT ts.CLUSTER_ID FROM ampx.traffic_source ats \n",
    "            JOIN domainpub.TS_CLUSTER ts ON ats.ID = ts.PUB_ATS_ID\n",
    "                where ats.publisher_id in (%s) and ats.level = 2\n",
    "                --and sub2 = 'newtab'\n",
    "                --and sub2 = 'filetaxes'\n",
    "                --and sub1 in ('10075')\n",
    "                --and sub2 not in (select distinct sub2\n",
    "                  --              from ampx.TRAFFIC_SOURCE ts \n",
    "                    --            join admindb_prod.PUBLISHER p on p.id = ts.PUBLISHER_ID \n",
    "                      --          where ts.PUBLISHER_ID = 12481\n",
    "                        --        and sub3 = '74319')\n",
    "                 --and ats.id not in (--SELECT distinct ts.id\n",
    "                                    --from domainpub.TS_CLUSTER tc \n",
    "                                    --join ampx.TRAFFIC_SOURCE ts on ts.id = tc.PUB_ATS_ID \n",
    "                                    --join domainpub.ADGROUP_DM_CLUSTER adc on adc.DM_CLUSTER_ID = tc.CLUSTER_ID \n",
    "                                    --join ampx.ADGROUP ad on ad.id = adc.ADGROUP_ID \n",
    "                                    --join ampx.CAMPAIGN ac on ac.id = ad.CAMPAIGN_ID \n",
    "                                    --join admindb_prod.PUBLISHER p on p.id = ts.PUBLISHER_ID \n",
    "                                    --where ts.PUBLISHER_ID in (12411)\n",
    "                                    --and ad.ACCOUNT_ID =74565\n",
    "                                    --and level =2 )\n",
    "                \"\"\"%str(para['pub_id'])[1:-1]\n",
    "\n",
    "para['clusters'] = pd.read_sql(sql,db)['CLUSTER_ID'].tolist()\n",
    "\n",
    "db.close()\n",
    "\n",
    "if len(para['pub_id']) == len(para['tag_id']):\n",
    "    print('Looks good. Move forward')\n",
    "else:\n",
    "    print('Is there any special pubs (one with multiple tag iDs) included. If yes, need to take them out')\n",
    "    \n",
    "print(len(para['tag_id']))\n",
    "print(len(para['clusters']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "para['clusters'].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(para['tag_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(para['ts_index'],'w') \n",
    "\n",
    "for i in para['sub3']:\n",
    "    for k in para['sub2']:\n",
    "        sub = str(k['publisher_id']) +'|'+ str(k['sub1']) +'|'+ str(k['sub2']) +'|'+ str(i)\n",
    "        file.writelines('%s\\n'%sub)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open(para['cluster_sql'].split('/')[-1],'w') # para['cluster_sql']\n",
    "# file.writelines('use ampx;\\n\\n')\n",
    "# for i in list(para['sub3'].keys()):\n",
    "#     file.writelines(\"UPDATE ACCOUNT SET EXTERNAL_NAME = 'Otto' WHERE ID = 74985;\\n\\n\"%(para['sub3'][i]['external'],i))\n",
    "# #     Update CDN Image URL \n",
    "#     file.writelines(\"INSERT INTO THUMBNAIL (DESCRIPTION, VERTICAL_ID, ACCOUNT_ID, CAMPAIGN_ID, ADGROUP_ID, ADCOPY_ID, IMAGE_URL, CREATED_TIME_STAMP, THUMBNAIL_STATUS_ID, THUMBNAIL_TYPE_ID) \\nVALUES('Account #%i', NULL, %i, NULL, NULL, NULL, '%s', NOW(), 1, 2);\"\\\n",
    "# #                     %(i,i,para['sub3'][i]['img']))\n",
    "\n",
    "file.writelines('\\n\\nuse dynamic_tiles;\\n\\n')\n",
    "\n",
    "for i in list(para['sub3'].keys()):\n",
    "    for k in para['tag_id']:\n",
    "        file.writelines('INSERT INTO DYNAMIC_TILES_TAG_SETTING (DYNAMIC_TILES_TAG_ID, ACCOUNT_ID, `ORDER`, CREATED_TIMESTAMP) VALUES(%s, %i, 10, now());\\n'%(k['sub1'],int(i)))\n",
    "    \n",
    "file.writelines('\\n\\n-- CLUSTER CREATION --\\n')\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for i in para['clusters']:\n",
    "    for k in list(para['sub3'].keys()):\n",
    "#         ad  = np.random.choice(para['sub3'][k]['kw'], 1, p=p)[0]\n",
    "        for j in range(len(para['sub3'][k]['kw'])):\n",
    "#             print(i)\n",
    "            ad = para['sub3'][k]['kw'][j]\n",
    "            file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES(%i, %i, now(), now(), %i);\\n'\n",
    "            %(ad['adgroup'],i,ad['kw']))\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches for RESTRUCTURE\n",
    "file = open(para['cluster_sql'].split('/')[-1],'w') # para['cluster_sql']\n",
    "\n",
    "file.writelines('\\n\\n-- CLUSTER CREATION --\\n')\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for i in para['clusters']:\n",
    "    for k in list(para['sub3'].keys()):\n",
    "#         ad  = np.random.choice(para['sub3'][k]['kw'], 1, p=p)[0]\n",
    "        for j in range(len(para['sub3'][k]['kw'])):\n",
    "#             print(i)\n",
    "            ad = para['sub3'][k]['kw'][j]\n",
    "            file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES(%i, %i, now(), now(), %i);\\n'\n",
    "            %(ad['adgroup'],i,ad['kw']))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Setup new feed or new category for existing feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_id': 12901, \n",
    "             'sample_pub': 12901,#12479,  \n",
    "             'tag_id': 10172,\n",
    "        'sub2': ['homepage'],\n",
    "        'ts_index':'ts_index_snackmedia_footballleagueworld_setup.log',\n",
    "       'cluster_sql':'snackmedia_footballleagueworld_setup_20220502.sql'}\n",
    "\n",
    "# only 25176 for home depoy '74437' needs to take out \n",
    "# only 74565 for samsung '74557','74513' are the 2 need to take out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT DISTINCT p.publisher_name, sub3\n",
    "FROM ampx.traffic_source ats\n",
    "join admindb_prod.publisher p on p.id = ats.publisher_id\n",
    "WHERE ats.PUBLISHER_ID = %i\n",
    "--and sub1 = '10128'\n",
    "and ats.level = 3\n",
    "\"\"\"%(para['sample_pub'])\n",
    "\n",
    "sub2 = pd.read_sql(sql,db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "para['sub3']=list(sub2['sub3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of sub3 from the sample pub and Tag ID for indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this one!\n",
    "\n",
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT DISTINCT  \n",
    "aa.name as adv, aa.ID as adv_id, ac.name as campaign, ad.CAMPAIGN_ID, da.ADGROUP_ID, da.KEYWORD_ID,\n",
    "ac.CAMPAIGN_STATUS_ID, ad.ADGROUP_STATUS_ID, ke.KEYWORD_STATUS_ID, ca.CATEGORY_STATUS_ID\n",
    "FROM ampx.ADGROUP ad \n",
    "JOIN domainpub.ADGROUP_DM_CLUSTER da on ad.id = da.ADGROUP_ID and da.dm_cluster_id > 2000000000\n",
    "JOIN domainpub.TS_CLUSTER ts on da.DM_CLUSTER_ID = ts.CLUSTER_ID\n",
    "JOIN domainpub.DM_CLUSTER dc on dc.id = ts.CLUSTER_ID AND dc.RESTRICTION_TYPE_ID = 3\n",
    "JOIN ampx.TRAFFIC_SOURCE ats on ats.id = ts.PUB_ATS_ID\n",
    "JOIN admindb_prod.PUBLISHER pub on pub.id = ats.PUBLISHER_ID\n",
    "JOIN ampx.ACCOUNT aa on aa.id = ad.account_id\n",
    "JOIN ampx.CAMPAIGN ac on ac.id = ad.CAMPAIGN_ID\n",
    "LEFT JOIN admindb_prod.PUBLISHER_FIXED_BID cpc on cpc.DP_CLUSTER_ID = ts.CLUSTER_ID\n",
    "LEFT JOIN ampx.KEYWORD ke on ke.id = da.KEYWORD_ID\n",
    "LEFT JOIN ampx.CATEGORY ca on ca.id = da.CATEGORY_ID\n",
    "WHERE ats.PUBLISHER_ID in (%s)\n",
    "and ats.level = 2\n",
    "and aa.id not in (74437,74495,74561,74447,74557,74557,74557,74513) -- Homedepot Decor, Mercedes Benz CPO, NSI, Samsung accounts\n",
    "-- and ac.CAMPAIGN_STATUS_ID = 1\n",
    "and ac.id not in (189862,212405,212459,215103,203551) -- Trivago brand campaign (we have tile cam now), Overstock, Experian (3 campaigns)\n",
    "and ke.id not in (338699153) -- Petsmart service tiles\n",
    "and ad.id not in (12249065)\n",
    "and ac.id not in (214705, 216679, 216681, 215603, 216683, 199184, 215093, 214707) -- Volvo campaign\n",
    "and aa.id not in (26026) -- Verizon not running tiles in Q3\n",
    "and aa.id not in (74433,74455) -- Samsung mobile performics, Sovrn Booking tile\n",
    "and ac.id not in (202099) -- Hotels' US campaign that CM don't want to matched any more\n",
    "-- and ad.ADGROUP_STATUS_ID = 1\n",
    " and aa.account_status_id = 1\n",
    "and lower(aa.external_name) not like '%%samsung%%'\n",
    "-- and (aa.ID in (select ACCOUNT_ID from adv) or aa.MANAGED_BY_FLIGHT_PLANS = 0)\n",
    "-- and aa.id = 73780\n",
    "\"\"\"%(str(para['sample_pub']))\n",
    "\n",
    "adv = pd.read_sql(sql,db)\n",
    "\n",
    "                            \n",
    "sql = \"\"\" select max(id) + 1 from domainpub.DM_CLUSTER \"\"\"\n",
    "cluster_1st = db.cursor().execute(sql).fetchall()[0][0]\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = adv.drop_duplicates(['ADGROUP_ID'],keep='first')\n",
    "adv.sort_values(by='adv',inplace=True)\n",
    "adv = adv.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(adv.adv_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adv.to_csv('asset_ff_banner.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating cluster checking for Dynamic Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"select distinct ts.PUBLISHER_ID ,ts.sub1,ts.sub2,ts.sub3, ts.id as ts_id, tc.CLUSTER_ID, adc.ID as clusterid\n",
    "from ampx.TRAFFIC_SOURCE ts \n",
    "join domainpub.TS_CLUSTER tc on tc.PUB_ATS_ID = ts.ID \n",
    "join domainpub.ADGROUP_DM_CLUSTER adc on adc.DM_CLUSTER_ID = tc.CLUSTER_ID \n",
    "join ampx.KEYWORD k on k.ID = adc.KEYWORD_ID\n",
    "where 1=1\n",
    "and PUBLISHER_ID in (12395,12747,12259,12299,12329,12115)\n",
    "--and ts.TS_PARENT_ID_SUB1 not in (select gb.TS_ID from ampx.GLOBAL_BLACKLIST gb )\n",
    "--and sub1 not in (SELECT distinct ats.SUB1 \n",
    "                        --from ampx.TRAFFIC_SOURCE ats\n",
    "                        --join ampx.GLOBAL_BLACKLIST bl on bl.ts_id = ats.ID \n",
    "                        --where ats.PUBLISHER_ID in (12845) and level = 1)\n",
    "--and ats.sub1 not in (select DISTINCT ts.sub1 from ampx.GLOBAL_BLACKLIST gb \n",
    "                          --join ampx.TRAFFIC_SOURCE ts on ts.id = gb.TS_ID\n",
    "                          --where ts.PUBLISHER_ID in (12359,12371))\n",
    "                       \n",
    "--and level = 2\n",
    "--and sub1 = '10156'\n",
    "--and sub2 = 'shopsponsoredbrands'\n",
    "--and sub3 = '74433'\n",
    "--and sub3 in ('1','2','3','4')\n",
    "--and sub4 in ('desktop','mobile')\n",
    "--and adc.ADGROUP_ID = 15411333\n",
    "and k.ID = 339529217\n",
    "order by 1,2\n",
    "\"\"\"\n",
    "\n",
    "ats_id = pd.read_sql(sql,db)\n",
    "\n",
    "cluster_id = ats_id['CLUSTER_ID'].to_list()\n",
    "\n",
    "id_of_cluster = ats_id['clusterid'].to_list()\n",
    "\n",
    "print(len(cluster_id))\n",
    "\n",
    "print(len(id_of_cluster))\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_of_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad= 14960135\n",
    "kw = 346924953"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update Assets without inserting TS into new assets, Ask for Permission before do UPDATING SQL\n",
    "file = open('samsungmobile_new_assets_20220427.sql','w') \n",
    "\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for i in cluster_id :\n",
    "    file.writelines('UPDATE ADGROUP_DM_CLUSTER \\n')\n",
    "    file.writelines('set ADGROUP_ID = , KEYWORD_ID = , MODIFIED_TIME_STAMP = now()\\n')\n",
    "    file.writelines('where ID in () \\n')\n",
    "    file.writelines('and ADGROUP_ID = \\n')\n",
    "    file.writelines('and KEYWORD_ID = \\n')\n",
    "    file.writelines('\\n')\n",
    "    #file.writelines('\\n\\n')       \n",
    "    \n",
    "                    \n",
    "#     break\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assets from a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = pd.read_csv('ff_mobile_feed_assets.csv')#,dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = adv.drop_duplicates(['ADGROUP_ID'],keep='first')\n",
    "adv.sort_values(by='adv',inplace=True)\n",
    "adv = adv.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=jzhu;PWD=Jay31415@')\n",
    "sql = \"\"\"\n",
    "SELECT ats.ID\n",
    "FROM admindb_prod.PUBLISHER p \n",
    "join ampx.TRAFFIC_SOURCE ats on ats.PUBLISHER_ID = p.ID \n",
    "where p.id = 12329\n",
    "and \"LEVEL\" =2\n",
    "--and sub2 = 'searchmanager' \n",
    "\"\"\"\n",
    "ats = pd.read_sql(sql,db)\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ats_l = list(ats.values)\n",
    "ats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ats_l)):\n",
    "    print(str(cluster_1st+i-1),ats_l[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of direct matches\n",
    "adv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Number of advertisers needed to be matched\n",
    "len(adv.adv_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = adv.iloc[:,1:7].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['sub3'] = adv['adv_id'].unique().tolist()\n",
    "print('# advs to match, hence # sub3 values %i'%len(para['sub3']))\n",
    "print('# of tag IDs: %i'%len(set(para['sub2'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para['sub3'] = adv['ID'].unique().tolist()\n",
    "# print('# advs to match, hence # sub3 values %i'%len(para['sub3']))\n",
    "# print('# of tag IDs: %i'%len(set(para['sub2'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a text file for indexing new traffic sources\n",
    "\n",
    "file = open(para['ts_index'],'w') \n",
    "\n",
    "for i in para['sub3']:\n",
    "    for k in para['sub2']:\n",
    "        sub = str(para['pub_id']) + '|' + str(para['tag_id']) + '|' + k + '|' + str(i)\n",
    "        file.writelines('%s\\n'%sub)\n",
    "#         print('%s\\n'%sub)\n",
    "    \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# number of TS to index: %i'%(len(para['sub3'])*len(para['sub2'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=jzhu;PWD=Jay31415@')\n",
    "sql = \"\"\"select ats.ID as ats_id from ampx.traffic_source ats \n",
    "            where ats.level = 2 and ats.publisher_id in (%s) and ats.sub2 in (%s)\n",
    "            --and date(ats.CREATED_TIME_STAMP) = current_date\n",
    "            \"\"\"%(str(para['pub_id']),str(para['sub2'])[1:-1])\n",
    "para['ats_id'] = pd.read_sql(sql,db)['ats_id'].tolist()\n",
    "\n",
    "sql = \"\"\" select max(id) + 1 from domainpub.DM_CLUSTER \"\"\"\n",
    "\n",
    "cluster_1st = db.cursor().execute(sql).fetchall()[0][0]\n",
    "\n",
    "db.close()\n",
    "\n",
    "if len(para['sub3']) * len(para['sub2']) == len(para['ats_id']):\n",
    "    print('Index sucessfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(para['ats_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['ats_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of TSs indexed: %i'%len(para['ats_id'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_1st =2001360719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['cluster_sql'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open(para['cluster_sql'],'w') \n",
    "file.writelines('use dynamic_tiles;\\n\\n')\n",
    "file.writelines('INSERT INTO DYNAMIC_TILES_TAG (ID, PUBLISHER_ID, CREATED_TIMESTAMP) VALUES (%i, %i, now());\\n\\n'\n",
    "                %(para['tag_id'],para['pub_id']))\n",
    "\n",
    "for i in para['sub3']:\n",
    "    file.writelines('INSERT INTO DYNAMIC_TILES_TAG_SETTING (DYNAMIC_TILES_TAG_ID, ACCOUNT_ID, `ORDER`, CREATED_TIMESTAMP) VALUES(%i, %i, 10, now());\\n'%(para['tag_id'],int(i)))\n",
    "    \n",
    "file.writelines('\\n\\n-- CLUSTER CREATION --\\n')\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for i in range(len(para['ats_id'])):\n",
    "    cluster = cluster_1st+i\n",
    "#     para['clusters'].append(cluster)\n",
    "    file.writelines('\\n\\nINSERT INTO DM_CLUSTER (ID, RESTRICTION_TYPE_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP) VALUES(%i, 3, now(), now());\\n'\n",
    "        %(cluster))\n",
    "    file.writelines('INSERT INTO TS_CLUSTER (PUB_ATS_ID, CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP) VALUES(%i, %i, now(), now());\\n'\n",
    "        %(para['ats_id'][i],cluster))\n",
    "    for k in range(len(adv)):\n",
    "        try:\n",
    "            file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES(%i, %i, now(), now(), %i);\\n'\n",
    "            %(adv['ADGROUP_ID'][k],cluster,adv['KEYWORD_ID'][k]))\n",
    "        except ValueError:\n",
    "            file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES(%i, %i, now(), now(), NULL);\\n'\n",
    "            %(adv['ADGROUP_ID'][k],cluster))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up assets tailed to each tile pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_names': ['umetiles','brandthunder_tiles','fes_tiles','mediavo_tiles','iac_tiles','spigot_toolbar_tiles','redbrick_tiles','mediavo_toolbar_tiles','avast_browser_tiles','cake_tiles','fes_toolbar_tiles','reachmobi_email_tiles','symbaloo_tiles2019','spigot_mobile_tiles','reachmobi_launcher_tiles','internal_tiles','salinasmedia_tiles','whitepages_desktop_tiles','whitepages_mobile_tiles','coinis_tiles','exploreads_extn_tiles','beestripe_browser_tiles','ff_tiles','apptap_tiles','iac_sites_tiles','oceanhero_extn_tiles','oceanhero_sites_tiles','klarnatiles','pmobiletiles','35dda4a9d3e038f31781','quadpaytiles','affirmtiles','xiaomitiles','oceanheromobiletiles','firefoxprivacytiles','nortontiles','kiwibrowsertiles','buttertiles','afterpaytiles','ziptilesapi','iackg'],\n",
    "       'sub3': [74713],\n",
    "        'adv': {\n",
    "            'reachmobi_launcher_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "                      , 'pmobiletiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "                      ,'mediavo_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "                ,'avast_browser_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "               ,'spigot_toolbar_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "                ,'spigot_mobile_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "#                ,'infinitynewtab_tiles': {'adgroup': 14823241,'kw': 338842029}\n",
    "                           ,'umetiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "                 ,'symbaloo_tiles2019': {'adgroup': 15411619,'kw': 351512919}\n",
    "                          ,'fes_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "              ,'mediavo_toolbar_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "                     ,'redbrick_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "                         ,'cake_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "#                 ,'linkury_tiles': {'adgroup': 14823299,'kw': 338842115}\n",
    "                 ,'brandthunder_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "#                 ,'spigot_sites_tiles': {'adgroup': 14823291,'kw': 338842065}\n",
    "               ,'ff_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "#                 ,'spigot_tiles2018': {'adgroup': 14823291,'kw': 338842065}\n",
    "#                 ,'imali_tiles': {'adgroup': 14823299,'kw': 338842115}\n",
    "                       ,'coinis_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "#                 ,'mymedia_tiles': {'adgroup': 14823295,'kw': 338842093}\n",
    "                  ,'fes_toolbar_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "#                 ,'spigot_tiles_intl': {'adgroup': 14823229,'kw': 338841807}\n",
    "#                 ,'choicehotels_tiles': {'adgroup': 14823295,'kw': 338842093}\n",
    "                ,'whitepages_mobile_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "                ,'reachmobi_email_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "                ,'whitepages_desktop_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "#                 ,'spigot_mac_toolbar_tiles': {'adgroup': 14823235,'kw': 338841857}\n",
    "                ,'salinasmedia_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "#                 ,'inquirer_tiles': {'adgroup': 14823289,'kw': 338842077}\n",
    "#                 ,'adaware_tiles': {'adgroup': 14823289,'kw': 338842077}\n",
    "                ,'iac_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "#                 ,'sspx_tiles': {'adgroup': 14823269,'kw': 338841949}\n",
    "                ,'exploreads_extn_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "                ,'apptap_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "                ,'beestripe_browser_tiles': {'adgroup': 15411619,'kw': 351512919}\n",
    "#                 ,'searchencrypt_tiles': {'adgroup': 14823189,'kw': 338841735}\n",
    "#                 ,'display_tiles': {'adgroup': 14823229,'kw': 338841807}\n",
    "#                 ,'savysoda_tiles': {'adgroup': 14823235,'kw': 338841857}\n",
    "            ,'35dda4a9d3e038f31781': {'adgroup': 15411619,'kw': 351512917}\n",
    "            ,'ziptilesapi': {'adgroup': 15411619,'kw': 351512921}\n",
    "            ,'internal_tiles':{'adgroup': 15411619,'kw': 351512919}\n",
    "            ,'iac_sites_tiles':{'adgroup': 15411619,'kw': 351512919}\n",
    "            ,'oceanhero_extn_tiles':{'adgroup': 15411619,'kw': 351512919}\n",
    "            ,'oceanhero_sites_tiles':{'adgroup': 15411619,'kw': 351512919}\n",
    "            ,'klarnatiles':{'adgroup': 15411619,'kw': 351512919}\n",
    "            ,'quadpaytiles':{'adgroup': 15411619,'kw': 351512919}\n",
    "            ,'affirmtiles':{'adgroup': 15411619,'kw': 351512919}\n",
    "            ,'xiaomitiles':{'adgroup': 15411619,'kw': 351512919}\n",
    "            ,'oceanheromobiletiles':{'adgroup': 15411619,'kw': 351512919}\n",
    "            ,'firefoxprivacytiles':{'adgroup': 15411619,'kw': 351512919}\n",
    "            ,'nortontiles':{'adgroup': 15411619,'kw': 351512919}\n",
    "            ,'kiwibrowsertiles':{'adgroup': 15411619,'kw': 351512919}\n",
    "            ,'buttertiles':{'adgroup': 15411619,'kw': 351512919}\n",
    "            ,'afterpaytiles':{'adgroup': 15411619,'kw': 351512919}\n",
    "            ,'iackg':{'adgroup': 15411619,'kw': 351512919}\n",
    "               },\n",
    "                'external':\"\", 'img':'',\n",
    "       'ts_index':'ts_index.log',\n",
    "       'cluster_sql':'./clusters/stubhub_newassets__tiles_20220413.sql'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "sql = \"\"\"\n",
    "select distinct publisher_id, sub1, sub2 from ampx.traffic_source ats \n",
    "join admindb_prod.PUBLISHER pub on pub.ID = ats.PUBLISHER_ID \n",
    "JOIN domainpub.TS_CLUSTER ts ON ats.ID = ts.PUB_ATS_ID \n",
    "where pub.publisher_name in (%s) and level = 2 and pub.pub_delivery_method_id = 3\n",
    "order by 1,2,3\n",
    "\"\"\"%str(para['pub_names'])[1:-1]\n",
    "\n",
    "sub2 = pd.read_sql(sql,db)\n",
    "\n",
    "para['sub2'] = sub2.to_dict('records')\n",
    "\n",
    "\n",
    "sql = \"\"\"SELECT DISTINCT ts.CLUSTER_ID,pub.publisher_name FROM ampx.traffic_source ats\n",
    "            join admindb_prod.PUBLISHER pub on pub.ID = ats.PUBLISHER_ID \n",
    "            JOIN domainpub.TS_CLUSTER ts ON ats.ID = ts.PUB_ATS_ID\n",
    "                where pub.publisher_name in (%s) and ats.level = 2\n",
    "                \"\"\"%str(para['pub_names'])[1:-1]\n",
    "\n",
    "clusters = pd.read_sql(sql,db)\n",
    "\n",
    "para['clusters'] = {}\n",
    "for i in para['pub_names']:\n",
    "#     print(i)\n",
    "    para['clusters'][i] = clusters[clusters.publisher_name == i]['CLUSTER_ID'].tolist()\n",
    "\n",
    "# sql = \"\"\"\n",
    "# SELECT pub.PUBLISHER_NAME, pub.INTERNAL_NAME, pub.id, tag.ID, ts.ID, ts.MODIFIED_TIMESTAMP\n",
    "# FROM adminDB_Prod.PUBLISHER pub\n",
    "# JOIN dynamic_tiles.DYNAMIC_TILES_TAG tag on tag.PUBLISHER_ID = pub.ID\n",
    "# left JOIN dynamic_tiles.DYNAMIC_TILES_TAG_SETTING ts on ts.DYNAMIC_TILES_TAG_ID = tag.ID and account_id = 74433\n",
    "# where ts.id is NULL and pub.active = 1 and pub.PUB_DELIVERY_METHOD_ID = 3\n",
    "# and pub.publisher_name in (%s)\n",
    "# \"\"\"%str(para['pub_names'])[1:-1]\n",
    "\n",
    "# tag_id = pd.read_sql(sql,db)\n",
    "\n",
    "# para['tag_id'] = tag_id[['tag.ID']].drop_duplicates().tolist()\n",
    "\n",
    "db.close()\n",
    "\n",
    "if len(sub2['sub1'].unique()) == len(para['pub_names']):\n",
    "    print('Looks good. Move forward')\n",
    "else:\n",
    "    print('Is there any special pubs (one with multiple tag iDs) included. If yes, need to take them out')\n",
    "    \n",
    "# print(len(para['tag_id']))\n",
    "print(len(para['clusters']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(para['pub_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(para['adv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['tag_id'] = [10034]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(para['ts_index'],'w') \n",
    "\n",
    "for i in para['sub3']:\n",
    "    for k in para['sub2']:\n",
    "        sub = str(k['publisher_id']) +'|'+ str(k['sub1']) +'|'+ str(k['sub2']) +'|'+ str(i)\n",
    "        file.writelines('%s\\n'%sub)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['cluster_sql']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open(para['cluster_sql'],'w') \n",
    "# file.writelines('use ampx;\\n\\n')\n",
    "# for i in para['sub3']:\n",
    "#     file.writelines(\"UPDATE ACCOUNT SET EXTERNAL_NAME = '%s' WHERE ID = %i;\\n\\n\"%(para['external'],i))\n",
    "# #     Update CDN Image URL \n",
    "#     file.writelines(\"INSERT INTO THUMBNAIL (DESCRIPTION, VERTICAL_ID, ACCOUNT_ID, CAMPAIGN_ID, ADGROUP_ID, ADCOPY_ID, IMAGE_URL, CREATED_TIME_STAMP, THUMBNAIL_STATUS_ID, THUMBNAIL_TYPE_ID) \\nVALUES('Account #%i', NULL, %i, NULL, NULL, NULL, '%s', NOW(), 1, 2);\"\\\n",
    "#                     %(i,i,para['img']))\n",
    "\n",
    "# file.writelines('\\n\\nuse dynamic_tiles;\\n\\n')\n",
    "\n",
    "# for k in para['tag_id']:\n",
    "#     file.writelines('INSERT INTO DYNAMIC_TILES_TAG_SETTING (DYNAMIC_TILES_TAG_ID, ACCOUNT_ID, `ORDER`, CREATED_TIMESTAMP) VALUES(%s, %i, 10, now());\\n'%(str(k),int(i)))\n",
    "    \n",
    "file.writelines('\\n\\n-- CLUSTER CREATION --\\n')\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for i in list(para['clusters'].keys()):\n",
    "    file.writelines('\\n\\n -- %s -- \\n\\n'%i)\n",
    "    for cluster in para['clusters'][i]:\n",
    "        file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES(%i, %i, now(), now(), %i);\\n'\n",
    "            %(para['adv'][i]['adgroup'],cluster,para['adv'][i]['kw']))\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "para['sub3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=jzhu;PWD=%s'%pwd)\n",
    "sql = \"\"\"\n",
    "SELECT distinct p.PUBLISHER_NAME , sub2, ts.id as ats_id, adc.id as id, tc.CLUSTER_ID, adc.ADGROUP_ID , adc.KEYWORD_ID \n",
    "from ampx.TRAFFIC_SOURCE ts \n",
    "join admindb_prod.PUBLISHER p on p.id = ts.PUBLISHER_ID\n",
    "join domainpub.TS_CLUSTER tc on tc.PUB_ATS_ID = ts.ID \n",
    "join domainpub.ADGROUP_DM_CLUSTER adc on adc.DM_CLUSTER_ID = tc.CLUSTER_ID \n",
    "join ampx.ADGROUP ad on ad.id = adc.ADGROUP_ID \n",
    "where ts.PUBLISHER_ID  in (12487)\n",
    "and level = 2\n",
    "and ad.ACCOUNT_ID = 74437\n",
    "\"\"\"\n",
    "\n",
    "ads = pd.read_sql(sql,db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "','.join([str(x) for x in ads['id'].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ads['sub2'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon 74301 connection on Missing TS of tile pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Amazon_74301_missing_tile_pub_TS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('amazon_74301_missing_tile_pubs.log','w') \n",
    "\n",
    "for i,j,k in zip(df['PUBLISHER_ID'],df['sub1'],df['sub2']):\n",
    "    sub = str(i) + '|' + str(j) + '|' + str(k) + '|' + str(74301)\n",
    "    file.writelines('%s\\n'%sub)\n",
    "#         print('%s\\n'%sub)\n",
    "    \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = 13467763\n",
    "kw = 311472949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('amazon_74301_missing_tile_pubs.sql','w') # para['cluster_sql']\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "for i in list(df['CLUSTER_ID']):\n",
    "        file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES(%i, %s, now(), now(), %i);\\n'\n",
    "        %(ad,i,kw))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(list(df['CLUSTER_ID'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon 74357 connection on Missing TS of tile pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('amazon_74357_desktop_pub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assests = pd.read_csv('amazon_74357_desktop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('amazon_74357_missing_tile_pubs.sql','w') # para['cluster_sql']\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "for i in list(df['CLUSTER_ID']):\n",
    "        for j,k in zip(df_assests['ADGROUP_ID'],df_assests['KEYWORD_ID']):\n",
    "            file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES(%i, %s, now(), now(), %i);\\n'\n",
    "            %(int(j),i,int(k)))\n",
    "        file.writelines('\\n')    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('amazon_74357_mobile_pub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assests = pd.read_csv('amazon_74357_mobile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('amazon_74357_missing_tile_pubs_mobile.sql','w') # para['cluster_sql']\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "for i in list(df['CLUSTER_ID']):\n",
    "        for j,k in zip(df_assests['ADGROUP_ID'],df_assests['KEYWORD_ID']):\n",
    "            file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES(%i, %s, now(), now(), %i);\\n'\n",
    "            %(int(j),i,int(k)))\n",
    "        file.writelines('\\n')    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=jzhu;PWD=Jay31415@')\n",
    "sql = \"\"\"\n",
    "SELECT distinct adc.DM_CLUSTER_ID \n",
    "from ampx.TRAFFIC_SOURCE ts \n",
    "join domainpub.TS_CLUSTER tc on tc.PUB_ATS_ID = ts.ID \n",
    "join domainpub.ADGROUP_DM_CLUSTER adc on adc.DM_CLUSTER_ID = tc.CLUSTER_ID \n",
    "where ts.PUBLISHER_ID = 12697 \n",
    "\"\"\"\n",
    "cluster = pd.read_sql(sql,db)\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['cluster'] = list(cluster['DM_CLUSTER_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open('sys1_tiles_4ADVs.sql','w') # para['cluster_sql']\n",
    "file.writelines('use ampx;\\n\\n')\n",
    "\n",
    "file.writelines('\\n\\nuse dynamic_tiles;\\n\\n')\n",
    "\n",
    "for i in list(adv['ID']):\n",
    "    file.writelines('INSERT INTO DYNAMIC_TILES_TAG_SETTING (DYNAMIC_TILES_TAG_ID, ACCOUNT_ID, `ORDER`, CREATED_TIMESTAMP) VALUES(%s, %i, 10, now());\\n'%(para['tag_id'],int(i)))\n",
    "    \n",
    "file.writelines('\\n\\n-- CLUSTER CREATION --\\n')\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for i,j in zip(adv['adgroup'],adv['keyword']):\n",
    "    for k in para['cluster']:\n",
    "        file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES(%i, %i, now(), now(), %i);\\n'\n",
    "            %(i,k,j))\n",
    "        \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('volvo-new-campaigns-adding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = list(df['DM_CLUSTER_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = [14884393,14884387]\n",
    "kw = [343114901,343114785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in zip(ad,kw):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open('vovlo_new_campaigns_20200731.sql','w') # para['cluster_sql']\n",
    "  \n",
    "file.writelines('\\n\\n-- CLUSTER CREATION --\\n')\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for k in cluster:\n",
    "    for i,j in zip(ad,kw):\n",
    "        file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES(%i, %i, now(), now(), %i);\\n'\n",
    "            %(i,k,j))\n",
    "        \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=jzhu;PWD=Jay31415@')\n",
    "sql = \"\"\"\n",
    "select *\n",
    "from ampx.account aa \n",
    "order by aa.id desc\n",
    "limit 1\n",
    "\n",
    "\"\"\"\n",
    "data = pd.read_sql(sql,db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.to_dict('i')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"{'execTimestamp': $STR_EXEC_TIMESTAMP',\n",
    "'spikeThreshold': '$SPIKE_THRESHOLD',\n",
    "'dropThreshold': '$DROP_THRESHOLD',\n",
    "'windowSizeMinutes': '$WINDOW_SIZE_MINUTES',\n",
    "'lookBackDays': 'LOOKBACK_DAYS'}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=e-vertica-dev-read.ame.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=vrt_dev;UID=anomaly_pipeline_app;PWD=anomaly_pipeline_app_123')\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT *\n",
    "from data_anomaly.ANOMAlY_ALERTS_LOG\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db():\n",
    "    return pyodbc.connect('DRIVER={Vertica};SERVER=e-vertica-dev-read.ame.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=vrt_dev;UID=anomaly_pipeline_app;PWD=anomaly_pipeline_app_123')\n",
    "\n",
    "def query_db(query):\n",
    "    cur = db().cursor()\n",
    "    cur.execute(query)\n",
    "    r = [dict((cur.description[i][0], value) \\\n",
    "               for i, value in enumerate(row)) for row in cur.fetchall()]\n",
    "    cur.connection.close()\n",
    "    return (r[0] if r else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query = query_db(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(my_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json_output = json.dump(my_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'output':my_query}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(a).replace('\\'', '\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
