{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\AppData\\Local\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import paramiko\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the directory to where the text file which stores vertica password is\n",
    "\n",
    "pwd = open('..//..//vertica-pwd.txt','r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Sub to connect exsisting ALLLLLLL ADVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the information for indexing from the Ticket and manually update it \n",
    "para = {'pub_id':[12903], \n",
    "        'ads': {},\n",
    "        'sub1': ['ulta','etsy','underarmour','bloomingdales','athleta','reebok','chewy','thebodyshop','michaelkors','macys','nike'],\n",
    "        'sub2': ['shopping'],\n",
    "        'sub3': ['dynamiclink'],\n",
    "        'sub4': [''],\n",
    "        'account_id': ['74843','74567','74609','74022','74875','73686','74319','74867','73804','8654','74521'],\n",
    "        'ts_level_to-copy-ad':3,\n",
    "        'ts_level_to-get-ts':3,\n",
    "        'sub-value-to-copy-ad':'sub1',\n",
    "        'sub-value-to-pass-ad':'sub1',        \n",
    "       'ts_index':'TS_index_nateals_newadvs_setup_11102022.log',\n",
    "       'cluster_sql':'./clusters/nateals_newadvs_setup_11102022.sql'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get the assets ready for direct match/manually update\n",
    "para['ads'] = {'Ulta': [{'ADGROUP_ID': 15411303, 'KEYWORD_ID': 353493583}],\n",
    "               'Etsy': [{'ADGROUP_ID': 14885621, 'KEYWORD_ID': 343200339}],\n",
    "               'Under Armour': [{'ADGROUP_ID': 14894795, 'KEYWORD_ID': 346260429}],\n",
    "               'Bloomingdales': [{'ADGROUP_ID': 15411653, 'KEYWORD_ID': 352243885}],\n",
    "               'Athleta': [{'ADGROUP_ID': 15416354, 'KEYWORD_ID': 353225226}],\n",
    "               'Reebok': [{'ADGROUP_ID': 14859161, 'KEYWORD_ID': 340076309}],\n",
    "               'Chewy': [{'ADGROUP_ID': 15412735, 'KEYWORD_ID': 353019311}],\n",
    "               'The Body Shop': [{'ADGROUP_ID': 15411545, 'KEYWORD_ID': 351482903}],\n",
    "               'Michael Kors': [{'ADGROUP_ID': 15416194, 'KEYWORD_ID': 353362975}],\n",
    "               'Macys': [{'ADGROUP_ID': 14966849, 'KEYWORD_ID': 350268077}],\n",
    "               'Nike': [{'ADGROUP_ID': 14785161, 'KEYWORD_ID': 339354625}]\n",
    "#                         {'ADGROUP_ID': 14966859, 'KEYWORD_ID': 347573853}]\n",
    "#                  'accessories': [{'ADGROUP_ID': 14882321, 'KEYWORD_ID': 343090897}],\n",
    "#                  'mattresses': [{'ADGROUP_ID': 14882319, 'KEYWORD_ID': 343090901}]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Connect to the Database to read the traffic source and cluster ID\n",
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;PWD=UID=ywang;PWD=ChangeMe!')\n",
    "# Need to check the TS level to connect cluster / one ADV may have different campaign on different TS (e.g. DL Vs Homepage)\n",
    "sql = \"\"\"SELECT DISTINCT \n",
    "to_char({0}) as sub,\n",
    " -- {1},\n",
    "-- lower(aa.external_name) as sub,\n",
    "da.ADGROUP_ID, da.KEYWORD_ID \n",
    "    FROM ampx.traffic_source ats \n",
    "    JOIN domainpub.TS_CLUSTER ts ON ats.ID = ts.PUB_ATS_ID\n",
    "    JOIN domainpub.ADGROUP_DM_CLUSTER da on da.DM_CLUSTER_ID = ts.CLUSTER_ID AND da.dm_cluster_id > 2000000000\n",
    "    JOIN ampx.ADGROUP ad on ad.id = da.ADGROUP_ID\n",
    "    LEFT JOIN ampx.KEYWORD kw on kw.id = da.KEYWORD_ID\n",
    "    JOIN ampx.CAMPAIGN ac on ac.id = ad.CAMPAIGN_ID\n",
    "    JOIN ampx.ACCOUNT aa on aa.id = ad.account_id\n",
    "    where ats.publisher_id in ({2}) and ats.level = {3}\n",
    "    --and sub2 like '%.uk%'\n",
    "    --and aa.account_status_id = 1\n",
    "    --and ac.campaign_status_id = 1\n",
    "    --and ad.adgroup_status_id = 1\n",
    "    --and kw.keyword_status_id = 1\n",
    "    --and sub4 != 'google'\n",
    "    --and sub2 like 'samsung%'\n",
    "    --and aa.id != 74605\n",
    "    order by 1\n",
    "            \"\"\".format(para['sub-value-to-copy-ad'].replace(',','||'),para['sub-value-to-copy-ad'],str(para['pub_id'])[1:-1],para['ts_level_to-copy-ad'])\n",
    "                       #str(para['account_id'])[1:-1])\n",
    "\n",
    "ads = pd.read_sql(sql,db)\n",
    "\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ads['subs'] = ads['sub2'] +ads['sub3']+ [str(x).replace('None','') for x in ads['sub4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads['sub'] = [str(x)+str(y).replace('None','') for x, y in zip(ads['sub2'],ads['sub3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ads.to_csv('avast_omnibox_assets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ads = pd.read_csv('avast_omnibox_assets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(set(zip(ads['sub2'],ads['sub3'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ads['sub'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "para['sub2']=ads['sub2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para['sub1']=list(ads['sub1'].unique())\n",
    "# para['sub3']=list(ads['sub3'].unique())\n",
    "# para['sub4']=list(ads['sub4'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = open(para['ts_index'],'w')\n",
    "\n",
    "# for i in ads['sub1'] : #,ads['sub2']):\n",
    "#     line = str(para['pub_id'][0]) + '|' + str(i) + '|' +str(para['sub2'][0]) # + '|' +  str(j)+ '|'\n",
    "#     print(line)\n",
    "#     file.writelines(line+'\\n')\n",
    "# file.close()\n",
    "# print('-'*80+'\\n')\n",
    "\n",
    "# for i,j in zip(ads[['sub2','sub3']].drop_duplicates()['sub2'],ads[['sub2','sub3']].drop_duplicates()['sub3']):\n",
    "#     line = str(para['pub_id'][0]) + '|' + str(para['sub1'][0]) + '|' + str(i) + '|' + str(j).replace('None','')+ '|'\n",
    "#     print(line)\n",
    "#     file.writelines(line+'\\n')\n",
    "# file.close()\n",
    "\n",
    "for i in para['sub1'] : #,ads['sub2']):\n",
    "    for j in para ['sub2']:\n",
    "        for k in para['sub3']:\n",
    "            for l in para['sub4']:\n",
    "                line = str(para['pub_id'][0]) + '|' + str(i) + '|' +str(j)  + '|' +  str(k)+ '|'+str(l)\n",
    "                print(line)\n",
    "                file.writelines(line+'\\n')\n",
    "file.close()\n",
    "\n",
    "# for sub1 in para['sub1']:\n",
    "#     for i,j in lst : #,ads['sub2']):\n",
    "#         line = str(para['pub_id'][0])+ '|' + str(sub1) + '|' + str(i) + '|' +str(j)  #+ '|' +  str(k).replace('None','')\n",
    "#         print(line)\n",
    "#         file.writelines(line+'\\n')\n",
    "# file.close()\n",
    "print('-'*80+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = ads[['sub','ADGROUP_ID','KEYWORD_ID']].set_index('sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ads.index.unique().tolist():\n",
    "#     print(i)\n",
    "    para['ads'][i] = ads[ads.index == i].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['ads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " para['sub2'] = [str(x) for x in para['sub2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;PWD=UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"SELECT DISTINCT to_char({0}) as sub,\n",
    "ats.ID FROM ampx.TRAFFIC_SOURCE ats \n",
    "WHERE ats.publisher_id IN ({1}) \n",
    "and date(ats.CREATED_TIME_STAMP) = current_date()\n",
    "and ats.sub1 IN ({2}) \n",
    "and ats.sub2 in ({3})\n",
    "and level =3\n",
    "-- and ((ats.\"LEVEL\" = 3 and ats.id not in (select distinct TS_PARENT_ID_SUB3 from ampx.TRAFFIC_SOURCE where PUBLISHER_ID = 12751 and date(CREATED_TIME_STAMP) = current_date )) or ats.level=4) \n",
    "order by 1\n",
    "\"\"\".format(para['sub-value-to-pass-ad'].replace(',','||'), str(para['pub_id'])[1:-1],str(para['sub1'])[1:-1], str(para['sub2'])[1:-1],para['ts_level_to-get-ts'])\n",
    "\n",
    "\n",
    "# print(sql)\n",
    "\n",
    "ats_id = pd.read_sql(sql,db)\n",
    "\n",
    "# ats_id.set_index('ID',inplace=True)\n",
    "\n",
    "# para['ats_id'] = ats_id.to_dict('index')\n",
    "\n",
    "# print(len(para['ats_id']))\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(para['sub1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ats_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ats_id['subs']  = [str(x)+str(y) for x, y in zip(ats_id['sub2'],ats_id['sub'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ats_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ats_id.set_index('ID',inplace=True)\n",
    "\n",
    "para['ats_id'] = ats_id[['sub']].to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "para['ats_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;;PWD=UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"SELECT max(ID)+1 from domainpub.DM_CLUSTER\"\"\"\n",
    "\n",
    "cluster_1st = db.cursor().execute(sql).fetchall()[0][0]\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_1st\n",
    "# cluster_1st = 2001371705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['cluster_sql'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open(para['cluster_sql'],'w') \n",
    "\n",
    "file.writelines('\\n\\n-- CLUSTER CREATION --\\n')\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for k in list(para['ats_id'].keys()):\n",
    "    i = para['ats_id'][k]['sub']\n",
    "    file.writelines('INSERT INTO DM_CLUSTER (ID, RESTRICTION_TYPE_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP) VALUES({}, 3, now(), now());'.format(cluster_1st))\n",
    "    file.writelines('\\n')\n",
    "\n",
    "    file.writelines('INSERT INTO TS_CLUSTER (PUB_ATS_ID, CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP) VALUES({0}, {1}, now(), now());'.format(k,cluster_1st))\n",
    "    file.writelines('\\n')\n",
    "     \n",
    "    for j in para['ads'][i]:      \n",
    "#         print(j)\n",
    "        file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES({0}, {1}, now(), now(), {2});'.format(j['ADGROUP_ID'],cluster_1st,j['KEYWORD_ID']))\n",
    "        file.writelines('\\n')\n",
    "    file.writelines('\\n\\n')       \n",
    "    \n",
    "    cluster_1st += 1\n",
    "                    \n",
    "#     break\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New ADV on One or more Pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_id':[12755], \n",
    "        'ads': {},\n",
    "        'sub1': ['yahoomail'],\n",
    "        'sub2': ['lookfantastic.com','myprotein.com'],\n",
    "        'sub3': ['1','2','3','4'],\n",
    "        'sub4': ['desktop','mobile'],\n",
    "        'account_id': [],\n",
    "        'ts_level_to-copy-ad':4,\n",
    "        'ts_level_to-get-ts':4,\n",
    "        'sub-value-to-copy-ad':'sub1',\n",
    "        'sub-value-to-pass-ad':'sub1',        \n",
    "       'ts_index':'TS_yahoomail_advs_index_11192024.txt',\n",
    "       'cluster_sql':'./clusters/yahoomail_advs_setup_11192024.sql'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_id':[12285], \n",
    "        'ads': {},\n",
    "        'sub1': ['thecontainerstore','tommybahama','ubereats','dermstore','everlane','hotels'],\n",
    "        'sub2': ['slickdeals'],\n",
    "        'sub3': ['dynamiclink'],\n",
    "        'sub4': [''],\n",
    "        'account_id': [],\n",
    "        'ts_level_to-copy-ad':3,\n",
    "        'ts_level_to-get-ts':3,\n",
    "        'sub-value-to-copy-ad':'sub1',\n",
    "        'sub-value-to-pass-ad':'sub1' ,       \n",
    "       'ts_index':'slickdeals_advs_02222024_index.txt',\n",
    "       'cluster_sql':'./clusters/slickdeals_advs_02222024_setup.sql'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_id':[13083], \n",
    "        'ads': {},\n",
    "        'sub1': ['web','app'],\n",
    "        'sub2': ['amazon','bestbuy','homedepot','ikea','tmobile','wayfair','ulta','nike','officedepot','macys','chewy','bedbathbeyond','thecontainerstore','forever21','fragrancenet','underarmour','saksoff5th','bloomingdales','newbalance','michaelkors','jcpenny','tommybahama','calvinklein','spanx','harrydavid','oldnavy','overstock','reebok','victoriasecret','1800flowers','rosssimons','1800contacts'],\n",
    "        'sub3': [''],\n",
    "        'sub4': [''],\n",
    "        'account_id': [],\n",
    "        'ts_level_to-copy-ad':2,\n",
    "        'ts_level_to-get-ts':2,\n",
    "        'sub-value-to-copy-ad':'sub2',\n",
    "        'sub-value-to-pass-ad':'sub2' ,       \n",
    "       'ts_index':'vetted_10292024_index.txt',\n",
    "       'cluster_sql':'./clusters/reviewed_newsub3_06202024_setup.sql'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_id':[12833], \n",
    "        'ads': {},\n",
    "        'sub1': ['wired.com','latimes.com','usnews.com','gq.com','wsj.com','washingtonpost.com','telegraph.co.uk'],\n",
    "        'sub2': ['tracking.feedmob.com'],\n",
    "        'sub3': ['homepage','dynamiclink'],\n",
    "        'sub4': [''],\n",
    "        'account_id': [],\n",
    "        'ts_level_to-copy-ad':3,\n",
    "        'ts_level_to-get-ts':3,\n",
    "        'sub-value-to-copy-ad':'sub2',\n",
    "        'sub-value-to-pass-ad':'sub2' ,       \n",
    "       'ts_index':'SU_uber_02222024_index.txt',\n",
    "       'cluster_sql':'./clusters/SU_uber_02222024_setup.sql'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_id':[12593], \n",
    "        'ads': {},\n",
    "        'sub1': ['mercedes'],\n",
    "        'sub2': ['carrier'],\n",
    "        'sub3': ['AT1lhrbw0yibonid4nvyd2fd0gb'],\n",
    "        'sub4': ['push'],\n",
    "        'account_id': [],\n",
    "        'ts_level_to-copy-ad':4,\n",
    "        'ts_level_to-get-ts':4,\n",
    "        'sub-value-to-copy-ad':'sub1',\n",
    "        'sub-value-to-pass-ad':'sub1',        \n",
    "       'ts_index':'apptap_mercedes_index_11142023.txt',\n",
    "       'cluster_sql':'./clusters/apptap_mercedes_setup_11142023.sql'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['ads'] = [\n",
    "        {'ADGROUP_ID': 15482791, 'KEYWORD_ID': 357840725},\n",
    "#         {'ADGROUP_ID': 15482745, 'KEYWORD_ID': 355642451},\n",
    "#         {'ADGROUP_ID': 15482641, 'KEYWORD_ID': 355364555},\n",
    "#         {'ADGROUP_ID': 15482633, 'KEYWORD_ID': 355366699},\n",
    "#         {'ADGROUP_ID': 15482173, 'KEYWORD_ID': 355164951},\n",
    "#         {'ADGROUP_ID': 15411545, 'KEYWORD_ID': 351482903},\n",
    "#         {'ADGROUP_ID': 15416354, 'KEYWORD_ID': 353225226},\n",
    "#         {'ADGROUP_ID': 15229609, 'KEYWORD_ID': 353367393},\n",
    "#         {'ADGROUP_ID': 14959739, 'KEYWORD_ID': 350512671},\n",
    "#         {'ADGROUP_ID': 15416793, 'KEYWORD_ID': 353368889},\n",
    "#         {'ADGROUP_ID': 10929054, 'KEYWORD_ID': 285129392},\n",
    "#         {'ADGROUP_ID': 14859145, 'KEYWORD_ID': 342721341},\n",
    "#         {'ADGROUP_ID': 15477007, 'KEYWORD_ID': 353942671},\n",
    "#         {'ADGROUP_ID': 15416240, 'KEYWORD_ID': 353208680},\n",
    "#         {'ADGROUP_ID': 15411629, 'KEYWORD_ID': 351512915},\n",
    "#         {'ADGROUP_ID': 15411313, 'KEYWORD_ID': 353659041},\n",
    "#         {'ADGROUP_ID': 15412805, 'KEYWORD_ID': 353367389},\n",
    "#         {'ADGROUP_ID': 15478441, 'KEYWORD_ID': 353988001},\n",
    "#         {'ADGROUP_ID': 15481481, 'KEYWORD_ID': 354137077},\n",
    "#         {'ADGROUP_ID': 15480533, 'KEYWORD_ID': 354119383},\n",
    "#         {'ADGROUP_ID': 15481477, 'KEYWORD_ID': 354137073},\n",
    "#         {'ADGROUP_ID': 15480529, 'KEYWORD_ID': 354119381}\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting all existing subs or placements from records\n",
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"SELECT DISTINCT \n",
    "to_char({0}) as sub\n",
    "-- lower(aa.external_name) as sub,\n",
    "    FROM ampx.traffic_source ats \n",
    "    JOIN domainpub.TS_CLUSTER ts ON ats.ID = ts.PUB_ATS_ID\n",
    "    JOIN domainpub.ADGROUP_DM_CLUSTER da on da.DM_CLUSTER_ID = ts.CLUSTER_ID AND da.dm_cluster_id > 2000000000\n",
    "    JOIN ampx.ADGROUP ad on ad.id = da.ADGROUP_ID\n",
    "    LEFT JOIN ampx.KEYWORD kw on kw.id = da.KEYWORD_ID\n",
    "    JOIN ampx.CAMPAIGN ac on ac.id = ad.CAMPAIGN_ID\n",
    "    JOIN ampx.ACCOUNT aa on aa.id = ad.account_id\n",
    "    where ats.publisher_id in ({1}) and ats.level = {2}\n",
    "    --and sub2 not in ('test')\n",
    "    --and sub1 not in ('hotukdeals','savoo')\n",
    "    --and aa.account_status_id = 1\n",
    "    --and ac.campaign_status_id = 1\n",
    "    --and ad.adgroup_status_id = 1\n",
    "    --and kw.keyword_status_id = 1\n",
    "    --and sub1 in ('chollometro.savings-united.com','20minutos.es','descuentos.abc.es','chollometro.com')\n",
    "    --and sub2 not in ('test','coupons.businessinsider.com')\n",
    "    --and sub2 !='mediabuy'\n",
    "    --and sub3 ='dynamiclink'\n",
    "    order by 1\n",
    "            \"\"\".format(para['sub-value-to-copy-ad'],str(para['pub_id'])[1:-1],para['ts_level_to-copy-ad'])\n",
    "                       #str(para['account_id'])[1:-1])\n",
    "\n",
    "ads = pd.read_sql(sql,db)\n",
    "\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Special Case\n",
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT distinct sub2 as sub\n",
    "from ampx.TRAFFIC_SOURCE ts \n",
    "where ts.PUBLISHER_ID = 12235\n",
    "and sub2 not in (SELECT distinct sub2\n",
    "                from ampx.TRAFFIC_SOURCE ts  \n",
    "                where ts.PUBLISHER_ID = 12235\n",
    "                and sub1 = 'reebok'\n",
    "                and \"LEVEL\" = 2)\n",
    "and \"LEVEL\" = 2\n",
    "\"\"\"\n",
    "ads = pd.read_sql(sql,db)\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VL case\n",
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT distinct sub1\n",
    "from ampx.TRAFFIC_SOURCE ts \n",
    "where ts.PUBLISHER_ID = 12359\n",
    "and sub1 not in (select distinct ts.sub1 from ampx.TRAFFIC_SOURCE ts join ampx.GLOBAL_BLACKLIST gb on gb.TS_ID = ts.id )\n",
    "and sub2 = 'wix'\n",
    "and sub3 = 'homepage'\n",
    "and LEVEL =3 \n",
    "\"\"\"\n",
    "ads = pd.read_sql(sql,db)\n",
    "\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VL case\n",
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"\n",
    "with a as (\n",
    "SELECT DISTINCT \n",
    "\tpub.id, pub.PUBLISHER_NAME,\n",
    "\tats.sub1,ats.sub2,ats.sub3,\n",
    "\tda.ADGROUP_ID ,da.KEYWORD_ID ,ac.name, ac.CAMPAIGN_STATUS_ID , ad.ADGROUP_STATUS_ID , ke.KEYWORD_STATUS_ID,\n",
    "\t\tcase when ke.DEST_URL like '%PATH%' then 'dynamic' else 'homepage' end as Asset_type\n",
    "--ats.sub1,\n",
    "--ats.sub2,ats.sub3,ad.CAMPAIGN_ID ,da.ADGROUP_ID ,da.KEYWORD_ID ,ac.CAMPAIGN_STATUS_ID , ad.ADGROUP_STATUS_ID , ke.KEYWORD_STATUS_ID --, ats.sub1,ats.sub2,ats.sub3, ats.CREATED_TIME_STAMP ,da.id,aa.NAME ,,da.CREATED_TIME_STAMP  \n",
    "FROM ampx.TRAFFIC_SOURCE ats\n",
    "JOIN domainpub.TS_CLUSTER ts on ats.id = ts.PUB_ATS_ID\n",
    "JOIN domainpub.ADGROUP_DM_CLUSTER da on da.DM_CLUSTER_ID = ts.CLUSTER_ID and da.dm_cluster_id > 2000000000\n",
    "JOIN ampx.ADGROUP ad  on ad.id = da.ADGROUP_ID\n",
    "JOIN admindb_prod.PUBLISHER pub on pub.id = ats.PUBLISHER_ID\n",
    "JOIN admindb_prod.PUB_DELIVERY_METHOD del on del.id = pub.PUB_DELIVERY_METHOD_ID\n",
    "JOIN ampx.ACCOUNT aa on aa.id = ad.account_id\n",
    "JOIN ampx.CAMPAIGN ac on ac.id = ad.CAMPAIGN_ID\n",
    "LEFT JOIN ampx.KEYWORD ke on ke.id = da.KEYWORD_ID\n",
    "--where (da.ADGROUP_ID = 14901191 and da.KEYWORD_ID = 346253805) \n",
    "--and da.id in (42149641,42149835,42149505,42149421,42149527,42149365,42149437,42149831,42149501,42149879,42149565,42149751,42149803,42149535,42149457,42149853,42149497,42149439,42149403,42149369,42149715,42149423,42149771,42149363,42149653,42149455,42149569,42149547,42149795,42149495,42149861,42149613,42149839,42149791,42149663,42149717,42149415,42149543,42149575,42149693,42149855,42149419,42149673,42149475,42149329,42149675,42149897,42149525,42149891,42149429,42149343,42149617,42149631,42149529,42149671,42149451,42149651,42149339,42149851,42149893,42149843,42149597,42149467,42149787,42149573,42149873,42149461,42149411,42149645,42149737,42149837,42149579,42149667,42149399,42149557,42149695,42149559,42149463,42149621,42149359,42149585,42149521,42149377,42149371,42149449,42149679,42149773,42149499,42149657,42149813,42149431,42149655,42149493,42149625,42149863,42149391,42149775,42149395,42149711,42149871,42149881,42149709,42149383,42149823,42149677,42149517,42149727,42149519,42149619,42149409,42149725,42149731,42149417,42149335,42149353,42149533,42149607,42149591,42149901,42149859,42149443,42149699,42149347,42149703,42149401,42149471,42149627,42149741,42149643,42149605,42149333,42149907,42149425,42149503,42149887,42149633,42149485,42149807,42149801,42149487,42149867,42149661,42149805,42149701,42149765,42149405,42149707,42149447,42149745,42149473,42149581,42149635,42149553,42149441,42149869,42149603,42149531,42149681,42149469,42149589,42149491,42149733,42149637,42149555,42149753,42149345,42149819,42149777,42149883,42149743,42149739,42149789,42149811,42149649,42149393,42149623,42149885,42149355,42149705,42149849,42149373,42149567,42149759,42149545,42149583,42149735,42149875,42149817,42149639,42149541,42149385,42149763,42149669,42149549,42149865,42149825,42149561,42149489,42149821,42149595,42149413,42149509,42149847,42149845,42149551,42149877,42149799,42149747,42149379,42149381,42149757,42149659,42149593,42149459,42149571,42149341,42149389,42149905,42149857,42149599,42149361,42149387,42149523,42149895,42149827,42149513,42149833,42149665,42149769,42149793,42149587,42149815,42149349,42149611,42149507,42149841,42149515,42149755,42149797,42149483,42149577,42149629,42149331,42149647,42149481,42149433,42149351,42149713,42149465,42149357,42149563,42149511,42149615,42149721,42149697,42149761,42149337,42149785,42149375,42149479,42149427,42149539,42149683,42149767,42149719,42149809,42149729,42149407,42149749,42149687,42149445,42149397,42149685,42149691,42149537,42149723,42149779,42149609,42149477,42149829,42149783,42149903,42149909,42149889,42149601,42149781,42149689,42149435,42149453,42149367,42149899)\n",
    "where ad.CAMPAIGN_ID in (211337)--215015,212425) \n",
    "and ats.PUBLISHER_ID = 12359\n",
    "and ats.sub1 not in (select DISTINCT ts.sub1\n",
    "\t\t\t\t\tfrom ampx.GLOBAL_BLACKLIST gb \n",
    "\t\t\t\t\tjoin ampx.TRAFFIC_SOURCE ts on ts.id = gb.TS_ID\n",
    "\t\t\t\t\twhere ts.PUBLISHER_ID = 12359)\n",
    "--where pub.id in (12359)\n",
    "--where da.id in (41366647,41366649,41366651)\n",
    "--where aa.id = 74161\n",
    "--and ke.DEST_URL like '%PATH%'\n",
    "--and sub2 = 'verizon'\n",
    "and pub.ACTIVE = 1\n",
    "--and pub.ID not in (12125,12121)\n",
    ")\n",
    "SELECT distinct SUB1 \n",
    "from ampx.TRAFFIC_SOURCE ts \n",
    "where ts.PUBLISHER_ID = 12359\n",
    "and ts.sub1 not in (select DISTINCT ts.sub1\n",
    "\t\t\t\t\tfrom ampx.GLOBAL_BLACKLIST gb \n",
    "\t\t\t\t\tjoin ampx.TRAFFIC_SOURCE ts on ts.id = gb.TS_ID\n",
    "\t\t\t\t\twhere ts.PUBLISHER_ID = 12359)\n",
    "and sub1 not in ('3998718','4926625','1534853','1623615','1643950','3201772','5208207','1643958','1621274','1528657','4139703','1621969','1623619','4926621','1528659','1706327','3989807','1704907','1567217','1610189','3885371','3997475','1519029','3989647','3601149','3722531','1608317','1637880','1962179','1698716','1303172','1573367','1650064','3251458','1604115','5114286','1529964','1769639','1601942','1527048','1596650','1300149','1595963','3351659','4961866','1883482','1676422','4439479','1659501','4283019','3606768','1676400','1758927','4013280','1918823','4867665','1926905','1534861')\n",
    "and sub1 not in (select distinct sub1 from a)\n",
    "\"\"\"\n",
    "ads = pd.read_sql(sql,db)\n",
    "\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel('yieldkit_als_setup.xlsx',dtype=str)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[4:]['adv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel('yahoomail_als_setup.xlsx')\n",
    "# para['sub2'] = list(set(df[4:]['adv'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['sub1'] = ads['sub'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['sub2'] = ads['sub'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(para['ts_index'],'w') \n",
    "\n",
    "for i in para['pub_id']:\n",
    "    for j in para['sub1']:\n",
    "            for k in para['sub2']:\n",
    "                    for l in para['sub3']:\n",
    "                            for m in para['sub4']:\n",
    "                                line = str(i) + '|' + str(j) + '|' + str(k) + '|' + str(l) + '|' + str(m)                           \n",
    "                                file.writelines('%s\\n'%line)\n",
    "# print(i,j,k,l)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in list(zip(ads['sub2'],ads['sub3'])):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = open(para['ts_index'],'w') \n",
    "\n",
    "for i in para['pub_id']:\n",
    "    for j in para['sub1']:\n",
    "            for k,l in list(zip(ads['sub2'],ads['sub3'])):\n",
    "                    for m in para['sub4']:\n",
    "                        line = str(i) + '|' + str(j) + '|' + str(k)+ '|' + str(l) + '|' + str(m)                           \n",
    "                        file.writelines('%s\\n'%line)\n",
    "\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"SELECT DISTINCT {0} as sub,\n",
    "ats.ID FROM ampx.TRAFFIC_SOURCE ats \n",
    "WHERE ats.publisher_id IN ({1}) \n",
    "and date(ats.CREATED_TIME_STAMP) = current_date () \n",
    "--and ats.sub1 IN ({2}) \n",
    "--and ats.sub2 in ({3})\n",
    "--and ats.sub3 in ('19')\n",
    "--and ats.sub3 = 'dynamiclink'\n",
    "--and ats.sub2 = 'tui'\n",
    "--and level = 3\n",
    "and level = ({4})\n",
    "--order by 1\n",
    "\"\"\".format(para['sub-value-to-pass-ad'].replace(',','||'),str(para['pub_id'])[1:-1],str(para['sub1'])[1:-1],\n",
    "           str(para['sub2'])[1:-1],para['ts_level_to-get-ts'])\n",
    "ats_id = pd.read_sql(sql,db)\n",
    "\n",
    "para['ats_id'] = ats_id['ID'].to_list()\n",
    "para['ats_id'].sort()\n",
    "print(len(para['ats_id']))\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ats_id.ID).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Special Case\n",
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT distinct id, sub1 as sub1, sub4 as sub4\n",
    "from ampx.TRAFFIC_SOURCE ts \n",
    "where ts.PUBLISHER_ID = 12751\n",
    "--and sub1 = 'bcbswashington'\n",
    "--and sub4 = 'display'\n",
    "and sub3 = 'fr'\n",
    "and sub2 = 'thebodyshop'\n",
    "\"\"\".format(para['sub-value-to-pass-ad'].replace(',','||'),str(para['pub_id'])[1:-1],str(para['sub1'])[1:-1],\n",
    "           str(para['sub2'])[1:-1],para['ts_level_to-get-ts'])\n",
    "ats_id = pd.read_sql(sql,db)\n",
    "\n",
    "para['ats_id'] = ats_id['id'].to_list()\n",
    "print(len(para['ats_id']))\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ats_id = ats_id.set_index('sub')\n",
    "lst = ats_id.to_dict('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('yieldkit_als_setup.xlsx',dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new = df[4:][['adv','Adgroup ID','Keyword ID']].set_index('adv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic = df[['sub2','Adgroup_ID','Keyword_ID']].set_index('sub2')\n",
    "\n",
    "dic = {}\n",
    "for i in df[4:][\"adv\"].tolist(): \n",
    "    dic[i] = list(zip(df[df[\"adv\"]==i][\"Adgroup ID\"],df[df[\"adv\"]==i][\"Keyword ID\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic[lst[1]['sub']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "para['ats_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"SELECT max(ID)+1 from domainpub.DM_CLUSTER\"\"\"\n",
    "\n",
    "cluster_1st = db.cursor().execute(sql).fetchall()[0][0]\n",
    "\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "sql = \"\"\"\n",
    "select distinct publisher_id, sub1, sub2, sub3 from ampx.traffic_source ats \n",
    "JOIN domainpub.TS_CLUSTER ts ON ats.ID = ts.PUB_ATS_ID \n",
    "where \n",
    "--ats.publisher_id in (%s) and level = 2\n",
    "ats.publisher_id = 12513\n",
    "and sub1 in ('1525083','1598242')\n",
    "--and sub2 = 'thebodyshop'\n",
    "and sub2 = '74437'\n",
    "--and sub3= 'dynamiclink'\n",
    "--and sub1 in ('10075')\n",
    "--and ats.PUBLISHER_ID||sub2 not in (select distinct publisher_id||sub2 from ampx.traffic_source ats where sub3 = 73812 and level =3 and PUBLISHER_ID in (12379,12361,12395,12339))\n",
    "order by 1,2,3\n",
    "\"\"\"%str(para['pub_id'])[1:-1]\n",
    "\n",
    "sub2 = pd.read_sql(sql,db)\n",
    "\n",
    "para['sub2'] = sub2.to_dict('records')\n",
    "\n",
    "##para['tag_id'] = sub2[['publisher_id','sub1']].drop_duplicates().to_dict('records')\n",
    "\n",
    "sub2 = pd.read_sql(sql,db)\n",
    "\n",
    "sql = \"\"\"SELECT DISTINCT ts.CLUSTER_ID FROM ampx.traffic_source ats \n",
    "            JOIN domainpub.TS_CLUSTER ts ON ats.ID = ts.PUB_ATS_ID\n",
    "                where  ats.publisher_id = 12513 and ats.level = 2\n",
    "                --and sub1 = 'yelp'\n",
    "                and sub1 in ('1525083','1598242')\n",
    "                --ats.publisher_id in (%s) and ats.level = 2\n",
    "                and sub2 = '74437'\n",
    "                --and sub2 = 'filetaxes'\n",
    "                --and sub3 = 'gb'\n",
    "                --and sub1 in ('10075')\n",
    "                --and sub2 not in (select distinct sub2\n",
    "                  --              from ampx.TRAFFIC_SOURCE ts \n",
    "                    --            join admindb_prod.PUBLISHER p on p.id = ts.PUBLISHER_ID \n",
    "                      --          where ts.PUBLISHER_ID = 12481\n",
    "                        --        and sub3 = '74319')\n",
    "                 --and ats.id not in (--SELECT distinct ts.id\n",
    "                                    --from domainpub.TS_CLUSTER tc \n",
    "                                    --join ampx.TRAFFIC_SOURCE ts on ts.id = tc.PUB_ATS_ID \n",
    "                                    --join domainpub.ADGROUP_DM_CLUSTER adc on adc.DM_CLUSTER_ID = tc.CLUSTER_ID \n",
    "                                    --join ampx.ADGROUP ad on ad.id = adc.ADGROUP_ID \n",
    "                                    --join ampx.CAMPAIGN ac on ac.id = ad.CAMPAIGN_ID \n",
    "                                    --join admindb_prod.PUBLISHER p on p.id = ts.PUBLISHER_ID \n",
    "                                    --where ts.PUBLISHER_ID in (12411)\n",
    "                                    --and ad.ACCOUNT_ID =74565\n",
    "                                    --and level =2 )\n",
    "                \"\"\"%str(para['pub_id'])[1:-1]\n",
    "\n",
    "para['clusters'] = pd.read_sql(sql,db)['CLUSTER_ID'].tolist()\n",
    "\n",
    "db.close()\n",
    "\n",
    "##if len(para['pub_id']) == len(para['tag_id']):\n",
    "    ##print('Looks good. Move forward')\n",
    "##else:\n",
    "    ##print('Is there any special pubs (one with multiple tag iDs) included. If yes, need to take them out')\n",
    "    \n",
    "##print(len(para['tag_id']))\n",
    "print(len(para['clusters']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cluster_1st = 2001374496\n",
    "cluster_1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open(para['cluster_sql'],'w') \n",
    "\n",
    "file.writelines('\\n\\n-- CLUSTER CREATION --\\n')\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for i in para['ats_id'] :\n",
    "    file.writelines('INSERT INTO DM_CLUSTER (ID, RESTRICTION_TYPE_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP) VALUES({}, 3, now(), now());'.format(cluster_1st))\n",
    "    file.writelines('\\n')\n",
    "\n",
    "    file.writelines('INSERT INTO TS_CLUSTER (PUB_ATS_ID, CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP) VALUES({0}, {1}, now(), now());'.format(i,cluster_1st))\n",
    "    file.writelines('\\n')   \n",
    "    for j in para['ads']:\n",
    "        file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES({0}, {1}, now(), now(), {2});'.format(j['ADGROUP_ID'],cluster_1st,j['KEYWORD_ID']))\n",
    "        file.writelines('\\n')\n",
    "    file.writelines('\\n\\n') \n",
    "    cluster_1st += 1\n",
    "                    \n",
    "#     break\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['ads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open('skl_samsungcrn_setup_20221012.sql','w') \n",
    "\n",
    "file.writelines('\\n\\n-- CLUSTER CREATION --\\n')\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for j in para['ads']:\n",
    "    for i in range(int(para['clusters'])):\n",
    "        file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES({0}, {1}, now(), now(), {2});'.format(j['ADGROUP_ID'],para['clusters'][i],j['KEYWORD_ID']))\n",
    "        file.writelines('\\n')\n",
    "        file.writelines('\\n\\n') \n",
    "\n",
    "#     break\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open('yieldkit_hotels_setup_20220309.sql','w') \n",
    "\n",
    "file.writelines('\\n\\n-- CLUSTER CREATION --\\n')\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for j in lst :\n",
    "    file.writelines('INSERT INTO DM_CLUSTER (ID, RESTRICTION_TYPE_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP) VALUES({}, 3, now(), now());'.format(cluster_1st))\n",
    "    file.writelines('\\n')\n",
    "    i=lst[j]\n",
    "    file.writelines('INSERT INTO TS_CLUSTER (PUB_ATS_ID, CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP) VALUES({0}, {1}, now(), now());'.format(str(i['ID']),cluster_1st))\n",
    "    file.writelines('\\n')   \n",
    "\n",
    "    file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES({0}, {1}, now(), now(), {2});'.format(dic[i['sub']]['ADGROUP_ID'],cluster_1st,dic[i['sub']]['KEYWORD_ID']))\n",
    "    file.writelines('\\n')\n",
    "    file.writelines('\\n\\n')       \n",
    "    \n",
    "    cluster_1st += 1\n",
    "                    \n",
    "#     break\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic[lst[0]['sub']][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open(para['cluster_sql'],'w') \n",
    "\n",
    "file.writelines('\\n\\n-- CLUSTER CREATION --\\n')\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for j in lst :\n",
    "    file.writelines('INSERT INTO DM_CLUSTER (ID, RESTRICTION_TYPE_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP) VALUES({}, 3, now(), now());'.format(cluster))\n",
    "    file.writelines('\\n')\n",
    "    i=lst[j]\n",
    "    file.writelines('INSERT INTO TS_CLUSTER (PUB_ATS_ID, CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP) VALUES({0}, {1}, now(), now());'.format(str(i['ID']),cluster))\n",
    "    file.writelines('\\n')   \n",
    "\n",
    "    for k in dic[i['sub']]:\n",
    "        file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES({0}, {1}, now(), now(), {2});'.format(k[0],cluster,k[1]))\n",
    "        file.writelines('\\n')\n",
    "    file.writelines('\\n\\n')       \n",
    "    \n",
    "    cluster += 1\n",
    "                    \n",
    "#     break\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADV update asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"select distinct ts.PUBLISHER_ID ,ts.sub1,ts.sub2,ts.sub3, ts.id as ts_id, tc.CLUSTER_ID \n",
    "from ampx.TRAFFIC_SOURCE ts \n",
    "join domainpub.TS_CLUSTER tc on tc.PUB_ATS_ID = ts.ID \n",
    "join domainpub.ADGROUP_DM_CLUSTER adc on adc.DM_CLUSTER_ID = tc.CLUSTER_ID \n",
    "where PUBLISHER_ID in (12755)\n",
    "--and ts.TS_PARENT_ID_SUB1 not in (select gb.TS_ID from ampx.GLOBAL_BLACKLIST gb )\n",
    "and sub1 not in (SELECT distinct ats.SUB1 \n",
    "                        from ampx.TRAFFIC_SOURCE ats\n",
    "                        join ampx.GLOBAL_BLACKLIST bl on bl.ts_id = ats.ID \n",
    "                        where ats.PUBLISHER_ID in (12359,12371) and level = 1)\n",
    "and level = 4\n",
    "--and sub1 = '10156'\n",
    "and sub2 = 'boots.com'\n",
    "--and sub3 = '74433'\n",
    "--and sub3 in ('1','2','3','4')\n",
    "--and sub4 in ('desktop','mobile')\n",
    "order by 1,2\n",
    "\"\"\"\n",
    "\n",
    "ats_id = pd.read_sql(sql,db)\n",
    "\n",
    "cluster_id = ats_id['CLUSTER_ID'].to_list()\n",
    "\n",
    "print(len(cluster_id))\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"SELECT distinct p.id, p.PUBLISHER_NAME , ts.SUB1 , ts.SUB2 , tc.CLUSTER_ID -- adc.ADGROUP_ID \n",
    "from ampx.TRAFFIC_SOURCE ts\n",
    "join admindb_prod.PUBLISHER p on p.id = ts.PUBLISHER_ID \n",
    "join domainpub.TS_CLUSTER tc on tc.PUB_ATS_ID = ts.TS_PARENT_ID_SUB2 \n",
    "join domainpub.ADGROUP_DM_CLUSTER adc on adc.DM_CLUSTER_ID = tc.CLUSTER_ID \n",
    "join ampx.ADGROUP ad on ad.id =adc.ADGROUP_ID \n",
    "where ts.sub3 = '74183'\n",
    "and p.ACTIVE = 1\n",
    "and p.PUB_DELIVERY_METHOD_ID = 10\n",
    "and ad.ACCOUNT_ID = 74183\n",
    "and p.id not in (12481)\n",
    "\"\"\"\n",
    "\n",
    "ats_id = pd.read_sql(sql,db)\n",
    "\n",
    "cluster_id = ats_id['CLUSTER_ID'].to_list()\n",
    "\n",
    "print(len(cluster_id))\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"SELECT distinct adc.ADGROUP_ID , adc.KEYWORD_ID , adc.DM_CLUSTER_ID \n",
    "from ampx.TRAFFIC_SOURCE ts\n",
    "join domainpub.TS_CLUSTER tc on tc.PUB_ATS_ID = ts.id\n",
    "join domainpub.ADGROUP_DM_CLUSTER adc on adc.DM_CLUSTER_ID = tc.CLUSTER_ID \n",
    "where ts.PUBLISHER_ID = 12845\n",
    "and ts.sub2  = 'shopsponsoredbrands'\n",
    "-- and sub1 not in (\n",
    "                SELECT DISTINCT SUB1\n",
    "                FROM ampx.TRAFFIC_SOURCE ats \n",
    "                JOIN ampx.GLOBAL_BLACKLIST bl on bl.TS_ID = ats.id\n",
    "                where ats.PUBLISHER_ID in (12359,12371)\n",
    "                and ats.level <= 2\n",
    "                )\n",
    "\"\"\"\n",
    "\n",
    "ats_id = pd.read_sql(sql,db)\n",
    "\n",
    "cluster_id = ats_id['DM_CLUSTER_ID'].to_list()\n",
    "\n",
    "print(len(cluster_id))\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating cluster checking for Dynamic Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"select distinct ts.PUBLISHER_ID ,ts.sub1,ts.sub2,ts.sub3, ts.id as ts_id, tc.CLUSTER_ID, adc.ID as clusterid\n",
    "from ampx.TRAFFIC_SOURCE ts \n",
    "join domainpub.TS_CLUSTER tc on tc.PUB_ATS_ID = ts.ID \n",
    "join domainpub.ADGROUP_DM_CLUSTER adc on adc.DM_CLUSTER_ID = tc.CLUSTER_ID \n",
    "join ampx.KEYWORD k on k.ID = adc.KEYWORD_ID\n",
    "where PUBLISHER_ID in (122)\n",
    "--and ts.TS_PARENT_ID_SUB1 not in (select gb.TS_ID from ampx.GLOBAL_BLACKLIST gb )\n",
    "and sub1 not in (SELECT distinct ats.SUB1 \n",
    "                        from ampx.TRAFFIC_SOURCE ats\n",
    "                        join ampx.GLOBAL_BLACKLIST bl on bl.ts_id = ats.ID \n",
    "                        where ats.PUBLISHER_ID in (12845) and level = 1)\n",
    "--and level = 2\n",
    "and sub1 = 'samsung'\n",
    "--and sub2 = 'shopsponsoredbrands'\n",
    "--and sub3 = '74433'\n",
    "--and sub3 in ('1','2','3','4')\n",
    "--and sub4 in ('desktop','mobile')\n",
    "--and adc.ADGROUP_ID = 15411333\n",
    "--and k.ID = 351451423\n",
    "order by 1,2\n",
    "\"\"\"\n",
    "\n",
    "ats_id = pd.read_sql(sql,db)\n",
    "\n",
    "cluster_id = ats_id['CLUSTER_ID'].to_list()\n",
    "\n",
    "id_of_cluster = ats_id['clusterid'].to_list()\n",
    "\n",
    "print(len(cluster_id))\n",
    "\n",
    "print(len(id_of_cluster))\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_of_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wix_asset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[[18,]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ad group id','keyword id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open('disneyplust_new_assets_20220414.sql','w') \n",
    "\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for i in cluster_id :\n",
    "    for j,k in zip(df['ad group id'],df['keyword id']):\n",
    "        file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES({0}, {1}, now(), now(), {2});'.format(j,i,k))\n",
    "        file.writelines('\\n')\n",
    "    #file.writelines('\\n\\n')       \n",
    "    \n",
    "                    \n",
    "#     break\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad= 15411333\n",
    "kw = 351451569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('chewy new asset for insertation.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = '15412813'\n",
    "kw = '303327629'\n",
    "cluster_id = list(df.DM_CLUSTER_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open('update_samsung_slickdeals_20220803.sql','w') \n",
    "\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "file.writelines('update ADGROUP_DM_CLUSTER set ADGROUP_ID = 15411333, KEYWORD_ID = 351451569, MODIFIED_TIME_STAMP = now() \n",
    "                WHERE ID IN (42306901,42306905,42306927,42306929,42379625,42306935,42306939,42379639,42306911,42306907,42306909,42306903,42306919,42306941,42306915,42306925) AND ADGROUP_ID = 14960135 AND KEYWORD_ID = 346924963;')     \n",
    "    \n",
    "                    \n",
    "#     break\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update Assets without inserting TS into new assets, Ask for Permission before do UPDATING SQL\n",
    "file = open('samsungmobile_new_assets_20220426.sql','w') \n",
    "\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for i in cluster_id :\n",
    "    file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES({0}, {1}, now(), now(), {2});'.format(ad,i,kw))\n",
    "    file.writelines('\\n')\n",
    "    #file.writelines('\\n\\n')       \n",
    "    \n",
    "                    \n",
    "#     break\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert New asset to exsisting cluster (Account Restructure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = [\n",
    "        {'ADGROUP_ID': 12348661, 'KEYWORD_ID': 303327625},\n",
    "#         {'ADGROUP_ID': 15622707, 'KEYWORD_ID': 357878017},\n",
    "#         {'ADGROUP_ID': 15001135, 'KEYWORD_ID': 349175843},\n",
    "#         {'ADGROUP_ID': 14959687, 'KEYWORD_ID': 346777953},\n",
    "#         {'ADGROUP_ID': 15229049, 'KEYWORD_ID': 349959965},\n",
    "#         {'ADGROUP_ID': 15229045, 'KEYWORD_ID': 349959961},\n",
    "# ,{'ADGROUP_ID':15229055, 'KEYWORD_ID':349959971}\n",
    "# ,{'ADGROUP_ID':15229047, 'KEYWORD_ID':349959963}\n",
    "# ,{'ADGROUP_ID':15229057, 'KEYWORD_ID':349959973}\n",
    "# ,{'ADGROUP_ID':15229043, 'KEYWORD_ID':349959959}\n",
    "# ,{'ADGROUP_ID':15229051, 'KEYWORD_ID':349959967}\n",
    "# ,{'ADGROUP_ID':15229053, 'KEYWORD_ID':349959969}\n",
    "# ,{'ADGROUP_ID':15229041, 'KEYWORD_ID':349959957}\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel('total_av_amply_cluster_id.xlsx')\n",
    "df = pd.read_csv('avast_browser_tiles_new_advs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_id = list(df['DM_CLUSTER_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=ywang;PWD=ChangeMe!')\n",
    "\n",
    "sql = \"\"\"SELECT distinct adc.DM_CLUSTER_ID \n",
    "from ampx.TRAFFIC_SOURCE ts\n",
    "Join admindb_prod.PUBLISHER pub on pub.id = ts.PUBLISHER_ID\n",
    "join domainpub.TS_CLUSTER tc on tc.PUB_ATS_ID = ts.id\n",
    "join domainpub.ADGROUP_DM_CLUSTER adc on adc.DM_CLUSTER_ID = tc.CLUSTER_ID \n",
    "Join ampx.ADGROUP ad  on ad.id = adc.ADGROUP_ID\n",
    "Join ampx.ACCOUNT aa on aa.id = ad.account_id\n",
    "where 1=1\n",
    "and ts.PUBLISHER_ID in (12759,12487,12219)\n",
    "--pub.PUB_DELIVERY_METHOD_ID = 3\n",
    "--and ts.ID in (317847186)\n",
    "--and aa.Name like '%Samsung%'\n",
    "--and aa.id = 74949\n",
    "--and ts.id in (318255897)\n",
    "--and ts.sub1 in ('yahoomail')\n",
    "--and ts.sub3 not in ('deeplink')\n",
    "--and ts.sub2 in ('samsung.com')\n",
    "--and ts.UI_SUB1_ID in (181,221,145,144,142,172)\n",
    "--and ts.sub1 in ('samsung-best-android-tablets','samsung-best-budget-laptops','samsung-best-chromebooks','samsung-best-computer-monitors','samsung-best-fitness-trackers','samsung-best-frame-tvs','samsung-best-kids-tablets','samsung-best-laptop-computers','samsung-best-laptops-for-college-students','samsung-best-laptops-under-500','samsung-best-qled-tvs','samsung-best-samsung-galaxy-tablets','samsung-best-samsung-laptops','samsung-best-samsung-smart-watches','samsung-best-samsung-tablets','samsung-best-samsung-tvs','samsung-best-sd-memory-cards','samsung-best-security-cameras','samsung-best-smart-tvs','samsung-best-smartwatches','samsung-best-tablets','samsung-best-tablets-under-200','samsung-best-tvs','samsung-best-wireless-chargers')\n",
    "and aa.id in (74131)\n",
    "--and ts.sub1 not like '%group%'\n",
    "--and ts.sub1 not in ('hotukdeals','savoo')\n",
    "--and adc.DM_CLUSTER_ID not in (2001346202,2001346203,2001346200,2001346201,2001346205)\n",
    "--and ts.sub2 in ('mercedes.com')\n",
    "--and ts.sub3 = ''\n",
    "--and ts.sub4 in ('desktop','mobile')\n",
    "--and sub1 not in ((select DISTINCT ts.sub1 \n",
    "--\t\t\t\t\tfrom ampx.GLOBAL_BLACKLIST gb \n",
    "--\t\t\t\t\tjoin ampx.TRAFFIC_SOURCE ts on ts.id = gb.TS_ID\n",
    "--\t\t\t\t\twhere ts.PUBLISHER_ID in (12371) ))\n",
    "--and ad.campaign_id in (217743)\n",
    "--and sub2 ='rakuten'\n",
    "--and level =4\n",
    "order by 1\n",
    "\"\"\"\n",
    "\n",
    "ats_id = pd.read_sql(sql,db)\n",
    "\n",
    "cluster_id = list(ats_id['DM_CLUSTER_ID'].unique())\n",
    "\n",
    "print(len(cluster_id))\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cluster_id=[2000160427]\n",
    "cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open('experian_dynamic_remapping_04262024.sql','w') \n",
    "\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for i in cluster_id :\n",
    "    for j in ads:\n",
    "        file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES({0}, {1}, now(), now(), {2});'.format(j['ADGROUP_ID'],i,j['KEYWORD_ID']))\n",
    "        file.writelines('\\n')\n",
    "#     file.writelines('\\n\\n')       \n",
    "    \n",
    "                    \n",
    "#     break\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open('skl_homedepotflooring_setup_20220719.sql','w') \n",
    "\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for i in cluster_id :\n",
    "    for j,k in zip(df['ADGROUP_ID'],df['KEYWORD_ID']):\n",
    "        file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES({0}, {1}, now(), now(), {2});'.format(j,i,k))\n",
    "        file.writelines('\\n')\n",
    "#     file.writelines('\\n\\n')       \n",
    "    \n",
    "                    \n",
    "#     break\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up based on csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = {'pub_id':[12513], \n",
    "        'ads': {},\n",
    "        'sub1': ['1525078'],\n",
    "        'sub2': ['casper'],\n",
    "        'sub3': ['dynamiclink'],\n",
    "        'sub4': ['mobile','desktop'],\n",
    "        'account_id': [''],\n",
    "        'ts_level_to-copy-ad':4,\n",
    "        'ts_level_to-get-ts':4,\n",
    "        'sub-value-to-copy-ad':'sub1',\n",
    "        'sub-value-to-pass-ad':'sub1',        \n",
    "       'ts_index':'BR_samsung_new_sub_structure_20201216.log',\n",
    "       'cluster_sql':'./clusters/BR_samsung_new_sub_structure_update_20201216.sql'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('samsung-br-setup-adding-more_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={}\n",
    "sub1 = df['SUB1'].to_list()\n",
    "for i,j in zip(sub1,df.iloc[:,4:].values):\n",
    "    dic[i]=[]\n",
    "    n=len(j)\n",
    "    k=0\n",
    "    while k<n:\n",
    "        if j[k]==j[k]:\n",
    "            dic[i].append([j[k],j[k+1]])\n",
    "            k+=2\n",
    "        else:\n",
    "            k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['sub1']=sub1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para['ads']=dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(para['ts_index'],'w') \n",
    "\n",
    "for i in para['pub_id']:\n",
    "    for j in para['sub1']:\n",
    "            for k in para['sub2']:\n",
    "                    for l in para['sub3']:\n",
    "                            for m in para['sub4']:\n",
    "                                line = str(i) + '|' + str(j) + '|' + str(k)+ '|' + str(l) + '|' + str(m)                           \n",
    "                                file.writelines('%s\\n'%line)\n",
    "        \n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initial Setup\n",
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=jzhu;PWD=%s'%pwd)\n",
    "\n",
    "sql = \"\"\"SELECT DISTINCT {0} as sub,\n",
    "ats.ID FROM ampx.TRAFFIC_SOURCE ats \n",
    "WHERE ats.publisher_id IN ({1}) \n",
    "--and date(ats.CREATED_TIME_STAMP) = current_date\n",
    "and ats.sub1 IN ({2}) \n",
    "and ats.sub2 in ({3})\n",
    "and level = ({4})\n",
    "order by 1\n",
    "\"\"\".format(para['sub-value-to-pass-ad'].replace(',','||'),str(para['pub_id'])[1:-1],str(para['sub1'])[1:-1],\n",
    "           str(para['sub2'])[1:-1],para['ts_level_to-get-ts'])\n",
    "\n",
    "ats_id = pd.read_sql(sql,db)\n",
    "\n",
    "ats_id.set_index('ID',inplace=True)\n",
    "\n",
    "para['ats_id'] = ats_id.to_dict('index')\n",
    "\n",
    "print(len(para['ats_id']))\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "para['ats_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=jzhu;PWD=%s'%pwd)\n",
    "\n",
    "sql = \"\"\"SELECT max(ID)+1 from domainpub.DM_CLUSTER\"\"\"\n",
    "\n",
    "cluster_1st = db.cursor().execute(sql).fetchall()[0][0]\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cluster_1st = 2000160427\n",
    "cluster_1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open(para['cluster_sql'],'w') \n",
    "\n",
    "file.writelines('\\n\\n-- CLUSTER CREATION --\\n')\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for k in list(para['ats_id'].keys()):\n",
    "    i = para['ats_id'][k]['sub']\n",
    "    file.writelines('INSERT INTO DM_CLUSTER (ID, RESTRICTION_TYPE_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP) VALUES({}, 3, now(), now());'.format(cluster_1st))\n",
    "    file.writelines('\\n')\n",
    "\n",
    "    file.writelines('INSERT INTO TS_CLUSTER (PUB_ATS_ID, CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP) VALUES({0}, {1}, now(), now());'.format(k,cluster_1st))\n",
    "    file.writelines('\\n')\n",
    "     \n",
    "    for j in para['ads'][i]:      \n",
    "#         print(j)\n",
    "        file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES({0}, {1}, now(), now(), {2});'.format(str(int(j[0])),cluster_1st,str(int(j[1]))))\n",
    "        file.writelines('\\n')\n",
    "    file.writelines('\\n\\n')       \n",
    "    \n",
    "    cluster_1st += 1\n",
    "                    \n",
    "#     break\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# update and insert new asset\n",
    "db = pyodbc.connect('DRIVER={Vertica};SERVER=w-vertica-read.sf.admarketplace.net;PORT=5433;\\\n",
    "                            DATABASE=amp;UID=jzhu;PWD=%s'%pwd)\n",
    "\n",
    "sql = \"\"\"SELECT distinct ats.sub1, tc.CLUSTER_ID as ID\n",
    "from ampx.TRAFFIC_SOURCE ats \n",
    "join domainpub.TS_CLUSTER tc on tc.PUB_ATS_ID = ats.ID \n",
    "WHERE ats.publisher_id IN ({1}) \n",
    "and ats.sub1 IN ({2}) \n",
    "and ats.sub2 in ({3})\n",
    "and level = ({4})\n",
    "order by 1\n",
    "\"\"\".format(para['sub-value-to-pass-ad'].replace(',','||'),str(para['pub_id'])[1:-1],str(para['sub1'])[1:-1],\n",
    "           str(para['sub2'])[1:-1],para['ts_level_to-get-ts'])\n",
    "\n",
    "ats_id = pd.read_sql(sql,db)\n",
    "\n",
    "ats_id.set_index('ID',inplace=True)\n",
    "\n",
    "para['clutser_id'] = ats_id.to_dict('index')\n",
    "\n",
    "print(len(para['clutser_id']))\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "para['clutser_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dynamic and direct matches\n",
    "file = open(para['cluster_sql'],'w') \n",
    "\n",
    "file.writelines('\\n\\n-- CLUSTER CREATION --\\n')\n",
    "file.writelines('\\nuse domainpub;\\n')\n",
    "\n",
    "for k in list(para['clutser_id'].keys()):\n",
    "    i = para['clutser_id'][k]['sub1']    \n",
    "    for j in para['ads'][i]:      \n",
    "#         print(j)\n",
    "        file.writelines('INSERT INTO ADGROUP_DM_CLUSTER (ADGROUP_ID, DM_CLUSTER_ID, CREATED_TIME_STAMP, MODIFIED_TIME_STAMP, KEYWORD_ID) VALUES({0}, {1}, now(), now(), {2});'.format(str(int(j[0])),k,str(int(j[1]))))\n",
    "        file.writelines('\\n')\n",
    "#     file.writelines('\\n')       \n",
    "                    \n",
    "#     break\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(int(dic['best-verizon-phones'][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic['samsung-best-5g-phones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_lst = ['64.42.178.10','64.59.88.3','104.37.172.19','103.102.163.170','104.227.246.234','103.107.199.90','81.17.22.58','43.251.180.18','94.229.76.250','64.42.177.194','155.254.18.113','165.73.240.226','103.62.49.104','172.107.241.251','172.107.217.187','14.1.29.58','116.206.73.34','151.106.12.194','200.25.1.36','146.0.235.122','172.107.194.138','103.1.213.154','185.57.62.186','142.54.184.58','103.201.129.42','203.10.98.250','5.101.147.138','185.25.48.251','103.107.199.114','64.59.88.4','185.94.236.118','203.10.98.242','185.94.236.109','77.223.142.246']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_lst = [11777,12243,12197,12329,12715]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_fmt = \"CALL WHITELIST_IP_ADDRESS('{0}', {1}, 0, 'DB-10671',@WL_ID);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pub_lst:\n",
    "    for j in ip_lst:\n",
    "        print(str_fmt.format(j,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
